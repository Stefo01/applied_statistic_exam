{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0W2d8kYVI3u"
   },
   "source": [
    "\n",
    "# **Libraries to be used**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Lkp-fcbVRvJ"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.colors import ListedColormap\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.decomposition import PCA  # sklearn is another famous py library\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, cut_tree, cophenet, fcluster\n",
    "from scipy.spatial.distance import pdist, squareform, cdist\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from matplotlib.colors import Normalize\n",
    "from scipy.stats import shapiro, bartlett, f_oneway, norm\n",
    "from scipy.stats import multivariate_normal\n",
    "import scipy.stats as stats\n",
    "from matplotlib.patches import Ellipse\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.datasets import load_iris, make_blobs, make_moons\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "plt.rcParams[\"figure.figsize\"] = (8,6)\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFRhcaNjVZQq"
   },
   "source": [
    "# Lab1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1kdNUgoViQc"
   },
   "outputs": [],
   "source": [
    "lista = [\"C\", 10, 4.0]\n",
    "lista.index(\"C\")       # it returns the index of that data\n",
    "# lista[init:step:end]\n",
    "\n",
    "# dictionary definition\n",
    "dd = dict(Rick=46,Bob=86,Fred=21)\n",
    "\n",
    "# data loading\n",
    "df = pd.read_csv('file_name.csv') # or pd.read_csv('tourists.txt', sep=' ')\n",
    "df.shape\n",
    "df.columns\n",
    "df.info() # most important one\n",
    "df.iloc[:, 2:] # selecting all datas (first :) from the sector 2:\n",
    "df[\"diabetes\"].value_counts() # frequency of values in a column\n",
    "df.value_counts(normalize=True) # count, per each cols, the values inside and normalize them\n",
    "df.value_counts().idxmax() # takes the max index\n",
    "df[\"some_col\"].unique() # group into array all unique values\n",
    "df['anaemia'].nunique() # number of unique values in a column, sense for categorical variables\n",
    "\n",
    "# Some statistics\n",
    "df[\"some_col\"].describe() # gives count, mean, std, min, 25% (quartile), 50%, 75%, max\n",
    "df[\"some_col\"].median()\n",
    "df[\"some_col\"].quantile(0.75)\n",
    "df[\"some_col\"].mean()\n",
    "df[\"some_col\"].max()\n",
    "df[\"some_col\"].min()\n",
    "df[\"some_col\"].var()\n",
    "df[\"some_col\"].std()\n",
    "\n",
    "# PLOTS:\n",
    "\n",
    "# also without colors, there are some default colors\n",
    "# barplot\n",
    "colors = ['#baddf5', '#cc2b2b']\n",
    "ax = sns.countplot(data=df, x='anaemia', palette=colors, hue='anaemia', legend=False) # takes a dataframe. hue parameter is that one you wanna see the distribution\n",
    "ax.set_title('Barplot anaemia')\n",
    "\n",
    "# Some event grouped by another one\n",
    "sns.countplot(data=df, x='DEATH_EVENT', palette=colors, hue='high_blood_pressure')\n",
    "\n",
    "\n",
    "# Pie Chart\n",
    "death_counts = df['DEATH_EVENT'].value_counts()\n",
    "plt.pie(death_counts, labels=death_counts.index, startangle=90, colors=colors)\n",
    "plt.title('Something if you want')\n",
    "plt.show()\n",
    "\n",
    "# Histogram\n",
    "plt.hist(df['something'], bins=5, edgecolor='black') # bins is the range\n",
    "plt.title('Age Distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "# or also\n",
    "sns.histplot(data=df, x='DEATH_EVENT', kde=True, alpha=.4, edgecolor=(1, 1, 1), linewidth=0.5, bins=10) # kde is kernel density estimation, alpha is transparency, edgecolor is the color of the edges of the bars, linewidth is the width of the edges\n",
    "\n",
    "\n",
    "# Scatterplot\n",
    "sns.scatterplot(data=df, x='bmi', y='ejection_fraction', hue='DEATH_EVENT')\n",
    "plt.title('Something')\n",
    "plt.show()\n",
    "\n",
    "# Box plot\n",
    "sns.boxplot(data=df, y='something', x='DEATH_EVENT', palette=colors, hue='DEATH_EVENT')\n",
    "plt.title('Score Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Line inside a scatterplot\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X[:,0], X[:,1], color='black')\n",
    "ax.axhline(mean_X[1], color='grey', linestyle='--') # horizontal line at the mean of the second variable\n",
    "ax.axvline(mean_X[0], color='grey', linestyle='--') # vertical line at the mean of the first variable\n",
    "x_line = np.linspace(ax.get_xlim()[0], ax.get_xlim()[1], 100)\n",
    "y_line = mean_X[1] - np.tan(theta)*mean_X[0] + np.tan(theta)*x_line\n",
    "ax.plot(x_line, y_line, linestyle='--', color='black')\n",
    "ax.scatter(mean_X[0] + np.cos(theta)*proj30, mean_X[1] + np.sin(theta)*proj30, color='red')\n",
    "plt.title('Projection along theta = pi/6')\n",
    "plt.show()\n",
    "\n",
    "# create subplots\n",
    "nrows = 4\n",
    "ncols = 2\n",
    "fig, ax = plt.subplots(nrows,ncols,figsize = (10,25))\n",
    "for i in range(10): # some number\n",
    "    plt.subplot(nrows,ncols,i+1)\n",
    "    # sns.boxplot(data=df, y=num_vars[i])\n",
    "    # title = 'Distribution : ' + num_vars[i]\n",
    "    # plt.title(title)\n",
    "plt.tight_layout() # avoid overlapping of subplots\n",
    "plt.show()\n",
    "\n",
    "numerical_vars = [\"some_class\", \"other_one\"] # df.select_dtypes(include=['float64', 'int64']).columns.tolist()  # select numerical variables\n",
    "# Covariance matrix\n",
    "cov_matrix = df[numerical_vars].cov()\n",
    "plt.figure(figsize=(12,9))\n",
    "sns.heatmap(cov_matrix, annot=True, cmap=\"Blues\")\n",
    "plt.title(\"Covariance matrix heatmap\")\n",
    "plt.show()\n",
    "\n",
    "# Normalization of covariance: correlation matrix\n",
    "corrmat = df[numerical_vars].corr()\n",
    "plt.figure(figsize=(12,9))\n",
    "sns.heatmap(corrmat, annot=True, cmap=\"Blues\")\n",
    "\n",
    "# multivariate normal N(mu,sig)\n",
    "X = np.random.multivariate_normal(mu=0, sig=[], n=100) # sig is cov matrix, n is number of observation\n",
    "\n",
    "\n",
    "# Create a covariance matrix (example: 5 variables with some correlation)\n",
    "cov_matrix = np.array([\n",
    "    [1.0, 0.8, 0.6, 0.4, 0.2],\n",
    "    [0.8, 1.0, 0.7, 0.5, 0.3],\n",
    "    [0.6, 0.7, 1.0, 0.6, 0.4],\n",
    "    [0.4, 0.5, 0.6, 1.0, 0.8],\n",
    "    [0.2, 0.3, 0.4, 0.8, 1.0]\n",
    "])\n",
    "\n",
    "mean_vector = np.zeros(5)  # Mean for each variable\n",
    "n_samples = 100  # Number of observations\n",
    "\n",
    "# Generate data from multivariate normal distribution\n",
    "X = np.random.multivariate_normal(mean_vector, cov_matrix, size=n_samples)\n",
    "X = pd.DataFrame(X, columns=[f\"Var{i+1}\" for i in range(X.shape[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4j7lECLtVkH_"
   },
   "source": [
    "# Lab2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0glU3BeUVqnU"
   },
   "outputs": [],
   "source": [
    "# PCA from Lab 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# --------------------------\n",
    "# Step 1: Standardize the data\n",
    "# --------------------------\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# --------------------------\n",
    "# Step 2: Perform PCA\n",
    "# the PCs have to be orthogonal to each other, so PCA is a linear transformation that finds the directions of maximum variance in the data\n",
    "# --------------------------\n",
    "\n",
    "n_components = 2  # Number of principal components\n",
    "pca = PCA(n_components=n_components)# possibile anche passargli random_state\n",
    "# Metodi contenuti:\n",
    "# - components_ : ndarray of shape (n_components, n_features)\n",
    "# - explained_variance_ : ndarray of shape (n_components,)\n",
    "# - explained_variance_ratio_ : ndarray of shape (n_components,)\n",
    "# - n_components_ : int\n",
    "# - n_samples_ : int\n",
    "X_pca = pca.fit_transform(X_scaled) # applica la PCA e riduce la dimensione\n",
    "\n",
    "# --------------------------\n",
    "# Step 3: PCA Results\n",
    "# --------------------------\n",
    "\n",
    "print(\"Original shape:\", X_scaled.shape)\n",
    "print(\"PCA-transformed shape:\", X_pca.shape)\n",
    "print(\"Standard deviation of the components:\", pca.explained_variance_)\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)  # Proportion of variance explained. Normalized to sum to 1\n",
    "print(\"Principal components (directions/loadings):\\n\", pca.components_) # components are the directions of maximum variance in the data, they are orthogonal to each other\n",
    "\n",
    "# Accessing the PCA (loadings) components (best way to interpret PCA)\n",
    "print(\"Principal components (loadings):\\n\", pca.components_.T) # Transpose to get variables as rows and components as columns\n",
    "\n",
    "# Standard deviations of the principal components\n",
    "pc_std_dev = np.sqrt(pca.explained_variance_)\n",
    "print(\"Standard deviations of the components:\", pc_std_dev)\n",
    "\n",
    "# Cumulative variance explained\n",
    "cumulative_explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "print(\"Cumulative proportion of explained variance:\", cumulative_explained_variance)\n",
    "\n",
    "# --------------------------\n",
    "# Step 4: Plot loadings (coefficients) for first 3 principal components\n",
    "# --------------------------\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(8, 12))\n",
    "for i, ax in enumerate(axes):\n",
    "    if i < pca.components_.shape[0]:  # Avoid indexing error if < 3 components\n",
    "        ax.bar(X_scaled.columns, pca.components_.T[:, i])\n",
    "        ax.set_xticks(range(len(X_scaled.columns)))\n",
    "        ax.set_xticklabels(X_scaled.columns, rotation=90)\n",
    "        ax.set_ylabel(f\"PC{i+1} Loading\")\n",
    "        ax.set_title(f\"Loadings for PC{i+1}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# else, plot first 4 PCs loadings (better visualization)\n",
    "load_food = pca.components_.T\n",
    "fig, axs = plt.subplots(4, 1, figsize=(8,12))\n",
    "for i in range(4):\n",
    "    axs[i].bar(df.columns, load_food[:, i]) # oppure: significant_loadings = np.where(np.abs(load_food[:, i]) < 0.3, 0, load_food[:, i])\n",
    "    axs[i].set_ylim([-1, 1])\n",
    "    axs[i].axhline(0, color='black', linewidth=1)\n",
    "    axs[i].set_title(f'Loadings PC {i+1}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --------------------------\n",
    "# Step 5: Plot explained variance (scree plot)\n",
    "# --------------------------\n",
    "\n",
    "plt.plot(np.arange(1, len(pca.explained_variance_)+1), pca.explained_variance_, marker='o')\n",
    "plt.title('Principal Component Variances')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --------------------------\n",
    "# Step 6: Additional Plots for Interpretation\n",
    "# --------------------------\n",
    "\n",
    "n_obs, n_vars = X.shape\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "cumulative_explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "print(\"Cumulative proportion of explained variance:\", cumulative_explained_variance)\n",
    "\n",
    "# 1. Variance of each principal component\n",
    "axs[0].plot(np.arange(1, len(pca.explained_variance_)+1), pca.explained_variance_, marker='o')\n",
    "axs[0].set_title('Principal Component Variances')\n",
    "axs[0].set_xlabel('Component')\n",
    "axs[0].set_ylabel('Variance')\n",
    "\n",
    "# 2. Variance of each original variable\n",
    "original_variances = X_scaled.var(ddof=1)\n",
    "axs[1].bar(X_scaled.columns, original_variances)\n",
    "axs[1].set_title('Original Variable Variances')\n",
    "axs[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Cumulative explained variance\n",
    "axs[2].plot(np.arange(1, len(cumulative_explained_variance)+1), cumulative_explained_variance, marker='o')\n",
    "axs[2].axhline(1.0, color='blue', linestyle='-')\n",
    "axs[2].axhline(0.8, color='blue', linestyle='--')\n",
    "axs[2].set_title('Cumulative Explained Variance')\n",
    "axs[2].set_xlabel('Number of Components')\n",
    "axs[2].set_ylabel('Cumulative Variance')\n",
    "axs[2].set_ylim(0, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VdP8Ip0VrgG"
   },
   "source": [
    "# Lab3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fikW27pqV3c8"
   },
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Hierarchical Clustering (identify some groups for datas)\n",
    "# part of unsupervised learning\n",
    "# ------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, cut_tree, cophenet, fcluster\n",
    "from scipy.spatial.distance import pdist, squareform, cdist\n",
    "from mpl_toolkits.mplot3d import Axes3D  # for 3D plots\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Dissimilar matrix using some distances\n",
    "\n",
    "\n",
    "iris_data = {} # dictionary\n",
    "iris4 = pd.DataFrame(iris_data.data, columns=iris_data.feature_names)\n",
    "\n",
    "# you can filter the data es: X_filtered = X[X[:, 1] > -5] # removed outliers\n",
    "\n",
    "iris_e = pdist(iris4, metric='euclidean') # euclidean distance\n",
    "iris_m = pdist(iris4, metric='cityblock') # cityblock distance\n",
    "iris_c = pdist(iris4, metric='canberra')  # canberra distance (more importance to more differences)\n",
    "\n",
    "# plot the distance matrix\n",
    "plt.imshow(squareform(iris_e), aspect='equal') # less subject to outlier\n",
    "plt.title(\"Euclidean Distance Matrix for Iris\")\n",
    "plt.xlabel(\"i\")\n",
    "plt.ylabel(\"j\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Perform the linkage:\n",
    "\n",
    "iris_es = linkage(iris_e, method='single') # simple distances. Works well for data where clusters are naturally spread out\n",
    "iris_ea = linkage(iris_e, method='average') # Complete linkage ensures clusters are tight and well-defined, finding more easily spherical clusters and naturally resisting outliers. Might over-fragment data when clusters have a natural spread\n",
    "iris_ec = linkage(iris_e, method='complete') # max distances tra punti del cluster. Average linkage is less sensitive to outliers compared to single linkage but more flexible than complete linkage\n",
    "iris_ew = linkage(iris_e, method='ward')  # explicity optimized for the WSS\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Plot dendrograms\n",
    "# the cluster have to be robust in point position change\n",
    "# there is an automatic threshold (0.7 of the max distance)\n",
    "# ------------------------------\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18,6))\n",
    "dendrogram(iris_es, ax=axs[0], no_labels=True) # plot of dendrogram for a specific linkage\n",
    "axs[0].set_title(\"Euclidean-Single\")\n",
    "dendrogram(iris_ec, ax=axs[1], no_labels=True, color_threshold=0.5) # color threshold if you want to change\n",
    "axs[1].set_title(\"Euclidean-Complete\")\n",
    "dendrogram(iris_ea, ax=axs[2], no_labels=True)\n",
    "axs[2].set_title(\"Euclidean-Average\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Cluster with a different k, plot the data to see\n",
    "\n",
    "k = 2 # change k come tu voglia\n",
    "\n",
    "cluster_ec = cut_tree(iris_ec, n_clusters=k).flatten()\n",
    "cluster_es = cut_tree(iris_es, n_clusters=k).flatten()\n",
    "cluster_ea = cut_tree(iris_ea, n_clusters=k).flatten()\n",
    "# after that, control if it is correct within the starting dataset\n",
    "fig, axs = plt.subplots(1,3, figsize=(15,5))\n",
    "axs[0].scatter(X[:,0], X[:,1], c=np.where(cluster_es==0, 'red','blue'), s=20)\n",
    "axs[0].set_title(\"Single linkage clusters\")\n",
    "axs[1].scatter(X[:,0], X[:,1], c=np.where(cluster_ea==0, 'red','blue'), s=20)\n",
    "axs[1].set_title(\"Average linkage clusters\")\n",
    "axs[2].scatter(X[:,0], X[:,1], c=np.where(cluster_ec==0, 'red','blue'), s=20)\n",
    "axs[2].set_title(\"Complete linkage clusters\")\n",
    "for ax in axs:\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Contingency Tables (how to interpret it)\n",
    "# ------------------------------\n",
    "\n",
    "print(\"Contingency table for Eucledian-single\")\n",
    "print(pd.crosstab(iris_data.target, cluster_es))\n",
    "print(\"Contingency table for avg\")\n",
    "print(pd.crosstab(iris_data.target, cluster_ea))\n",
    "print(\"Contingency table for Eucledian-complete\")\n",
    "print(pd.crosstab(iris_data.target, cluster_ec))\n",
    "\n",
    "# pairplot for clusters\n",
    "iris4['Cluster'] = cluster_es\n",
    "palette = {0: 'red', 1: 'blue'}\n",
    "sns.pairplot(iris4, hue=\"Cluster\", diag_kind=\"kde\", palette=palette, markers=[\"o\", \"s\"])\n",
    "plt.suptitle(\"Iris Clustering (Single Linkage)\", y=1.02)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Cophenetic Correlations\n",
    "# The cophenetic distance between two points in a hierarchical clustering tree (dendrogram) is the height at which they are merged into the same cluster\n",
    "# The cophenetic correlation coefficient measures how well the hierarchical clustering structure preserves the original pairwise distances, computing the correlation between $D$ and $C\n",
    "# ------------------------------\n",
    "\n",
    "coph_es, coph_dists_es = cophenet(iris_es, iris_e) # first one is ccc, cooperating distance metric\n",
    "coph_ec, coph_dists_ec = cophenet(iris_ec, iris_e) # vicino a 1 buono, zero brutto\n",
    "coph_ea, coph_dists_ea = cophenet(iris_ea, iris_e)\n",
    "\n",
    "# ------------------------------\n",
    "# Internal Metrics: WSS and BSS\n",
    "# useful to select random clusters\n",
    "# ------------------------------\n",
    "\n",
    "# WSS: some to be small\n",
    "# BSS: max it\n",
    "\n",
    "def compute_wss_bss(x, merges, k_values):\n",
    "    wss_values = {}\n",
    "    bss_values = {}\n",
    "\n",
    "    overall_mean = np.mean(x, axis=0)  # Compute global mean\n",
    "\n",
    "    for k in k_values:\n",
    "        clustering = fcluster(merges, k, criterion='maxclust')\n",
    "        # computes centroids for all clusters\n",
    "        centroids = [np.mean(x[clustering==c],axis=0) for c in range(1,k+1)]\n",
    "        cluster_sizes = [len(x[clustering==c]) for c in range(1,k+1)]\n",
    "        # computes the euclidean distance between each point and each centroid\n",
    "        D = cdist(x, centroids, 'euclidean')\n",
    "        # find nearest centroid for each point\n",
    "        cIdx = np.argmin(D,axis=1)\n",
    "        # store the distances to the nearest centroid\n",
    "        d = np.min(D,axis=1)\n",
    "\n",
    "        # WSS\n",
    "        wss = sum(d**2)\n",
    "\n",
    "        # BSS\n",
    "        bss = np.sum([size * np.sum((centroid - overall_mean) ** 2) for size, centroid in zip(cluster_sizes, centroids)])\n",
    "\n",
    "        wss_values[k] = wss\n",
    "        bss_values[k] = bss\n",
    "    return wss_values,bss_values\n",
    "\n",
    "\n",
    "def compute_wss_bss_kmeans(x, k_values):\n",
    "    wss_values = {}\n",
    "    bss_values = {}\n",
    "\n",
    "    overall_mean = np.mean(x, axis=0)\n",
    "    total_ss = np.sum((x - overall_mean) ** 2)\n",
    "\n",
    "    for k in k_values:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42).fit(x)\n",
    "        wss = kmeans.inertia_  # WSS\n",
    "        bss = total_ss - wss   # Total SS = BSS + WSS\n",
    "        wss_values[k] = wss\n",
    "        bss_values[k] = bss\n",
    "\n",
    "    return wss_values, bss_values\n",
    "\n",
    "\n",
    "# How to use that (plot WSS and BSS)\n",
    "\n",
    "k_values = range(1,20) # cerca tra 1 e 20 clustering\n",
    "wss_dict, bss_dict = compute_wss_bss(iris4, iris_es, k_values)\n",
    "wss_values = [wss_dict[x] for x in range(1,20)]\n",
    "bss_values = [bss_dict[x] for x in range(1,20)]\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "font = {'family' : 'sans', 'size'   : 16}\n",
    "plt.rc('font', **font)\n",
    "plt.plot(k_values, wss_values, 'bo-', color='red', label='WSS')\n",
    "plt.plot(k_values, bss_values, 'bo-', color='blue', label='BSS')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('BSS & WSS')\n",
    "plt.xticks(k_values)\n",
    "plt.legend()\n",
    "plt.title('Hierarchical Clustering')\n",
    "\n",
    "\n",
    "# describe grouping by clusters\n",
    "iris4['Cluster'] = cluster_ea\n",
    "iris4.groupby('Cluster').describe()\n",
    "\n",
    "# ------------------------------\n",
    "# Snakes plots\n",
    "# ------------------------------\n",
    "\n",
    "# First standardize data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "normalized_iris = scaler.fit_transform(iris4)\n",
    "df_iris_normalized = pd.DataFrame(normalized_iris,columns=iris4.columns)\n",
    "df_iris_normalized['Cluster'] = cluster_ea\n",
    "\n",
    "df_iris_melt = pd.melt(df_iris_normalized,\n",
    "                    id_vars=['Cluster'],\n",
    "                    value_vars=iris4.columns,\n",
    "                    var_name='Attribute',\n",
    "                    value_name='Value')\n",
    "df_iris_melt\n",
    "\n",
    "# plot it\n",
    "\n",
    "sns.set_theme(rc={'figure.figsize':(12,8)})\n",
    "\n",
    "sns.lineplot(x=\"Attribute\", y=\"Value\", hue='Cluster', data=df_iris_melt)\n",
    "\n",
    "plt.title('Snake plot of standardized variables')  # <- move this here\n",
    "plt.legend(loc='center right', bbox_to_anchor=(1.25, 0.5), ncol=1, title='Cluster')\n",
    "plt.tight_layout()  # optional: prevents clipping of legend\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pc6JXIGgV49C"
   },
   "source": [
    "# Lab4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H-iR2FfMWAvv"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# example dataset for this\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m quakes \u001b[38;5;241m=\u001b[39m \u001b[43msm\u001b[49m\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mget_rdataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquakes\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m      3\u001b[0m Q \u001b[38;5;241m=\u001b[39m quakes\u001b[38;5;241m.\u001b[39miloc[:, :\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      4\u001b[0m Q[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mquakes\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sm' is not defined"
     ]
    }
   ],
   "source": [
    "# example dataset for this\n",
    "quakes = sm.datasets.get_rdataset(\"quakes\", \"datasets\").data\n",
    "Q = quakes.iloc[:, :2].copy()\n",
    "Q['depth'] = -quakes.iloc[:, 2] / 100\n",
    "\n",
    "\n",
    "# From lab 4: K-means and GMM\n",
    "\n",
    "# ------------------------------\n",
    "# K-means\n",
    "# most used clustering alg. two stop criteria: convergence criteria or max_iter\n",
    "# It works well only with euclidean distance (one limitation)\n",
    "# It works if there are globular cluster shapes\n",
    "# ------------------------------\n",
    "\n",
    "data_colors = ['#a6cdf6','#b2d0b7','#f98ea1']\n",
    "background_cmap3 = ListedColormap(['#a6cdf6','#b2d0b7','#f98ea1'])\n",
    "centroid_colors = ['#1b80e8','#599062','#e20c32']\n",
    "centroid_cmap = ListedColormap(centroid_colors)\n",
    "\n",
    "model = KMeans(n_clusters=3, random_state=42).fit(X)\n",
    "# - n_clusters=8\n",
    "# - init='k-means++'\n",
    "# - n_init='auto', is consecutive runs in terms of inertia\n",
    "# - max_iter=300 \n",
    "# - tol=0.0001 \n",
    "# - verbose=0 \n",
    "# - random_state=None \n",
    "# - copy_x=True \n",
    "# - algorithm='lloyd'\n",
    "# There are methods like:\n",
    "# - cluster_centers_ -> ndarray of shape (n_clusters, n_features)\n",
    "# - labels_ -> ndarray of shape (n_samples,)\n",
    "# - fit_predict(X) -> predict cluster index for each sample\n",
    "# - fit_transform(X) -> Compute clustering and transform X to cluster-distance space\n",
    "# - get_feature_names_out()\n",
    "# - inertia_ -> return the WSS\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "plt.subplot(323)\n",
    "plt.scatter(X[:, 0], X[:, 1], s=50, c=[data_colors[y] for y in y_pred], cmap=background_cmap3)\n",
    "plt.scatter(model.cluster_centers_[:,0], model.cluster_centers_[:,1], marker='*', s=200,\n",
    "            c=centroid_colors[:len(model.cluster_centers_)], cmap=centroid_cmap)\n",
    "plt.title(\"Unequal Variance\")\n",
    "\n",
    "\n",
    "\n",
    "# Another method\n",
    "\n",
    "kmeans_result = KMeans(n_clusters=2, init='k-means++', random_state=42, n_init=1).fit(Q)\n",
    "\n",
    "# some usefull params\n",
    "print(\"K-means clusters (Earthquakes):\\n\", kmeans_result.labels_) # are clusters assignments\n",
    "print(\"K-means centers:\\n\", kmeans_result.cluster_centers_)       # centroids coordinates\n",
    "\n",
    "\n",
    "# Find optimal parameter for k in kmeans (Using the same function of up about BSS and WSS)\n",
    "# About this, use the elbow method\n",
    "# With this you can select some possibility for k and, after that, tring to plot using the silhouette score\n",
    "\n",
    "w = []\n",
    "b = []\n",
    "Q_values = Q.values\n",
    "totss = np.sum((Q_values - Q_values.mean(axis=0))**2)\n",
    "for k_val in range(1, 11):\n",
    "    km = KMeans(n_clusters=k_val, init='k-means++', random_state=42, n_init=1).fit(Q)\n",
    "    withinss = km.inertia_ # WSS computed\n",
    "    between_ss = totss - withinss # BSS computed\n",
    "    w.append(withinss)\n",
    "    b.append(between_ss)\n",
    "ratio = np.array(w) / (np.array(w) + np.array(b))\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(range(1, 11), ratio, marker='o', linewidth=2)\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Within / Total variability\")\n",
    "plt.title(\"Choice of k using variability ratio\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Re-run for k-means\n",
    "\n",
    "kmeans_result4 = KMeans(n_clusters=4, random_state=42).fit(Q)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(Q.iloc[:,0], Q.iloc[:,1], c=kmeans_result4.labels_+1, s=50)\n",
    "plt.title(\"Earthquakes Data K-means Clustering (4 clusters)\")\n",
    "plt.xlabel(\"Latitude\")\n",
    "plt.ylabel(\"Longitude\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# we can also estimate the k of kmeans using another metric, the silhouette score.\n",
    "# A value close to +1 indicates a good clustering (in general, the value is in [-1, 1])\n",
    "\n",
    "# ------------------------------\n",
    "# K-means using silhouette score\n",
    "# compute silhouette for each point. easy\n",
    "# ------------------------------\n",
    "\n",
    "X = iris.iloc[:, :4].values # my new dataset\n",
    "\n",
    "range_n_clusters = [2, 3, 4, 5, 6] # k possible values\n",
    "# graphically plot the silouhette\n",
    "for n_clusters in range_n_clusters:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg) # this is the avg\n",
    "\n",
    "    # Compute the silhouette scores for each sample. THIS IS THE REAL COMPUTATION\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    ax2.scatter(X[:, 0], X[:, 1], marker='.', s=100, lw=0, alpha=1,\n",
    "                c=colors, edgecolor='k')\n",
    "\n",
    "    # Labeling the clusters\n",
    "    centers = clusterer.cluster_centers_\n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
    "                    s=50, edgecolor='k')\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"Feature space for the 1st feature (sepal length)\")\n",
    "    ax2.set_ylabel(\"Feature space for the 2nd feature (sepal width)\")\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# --------------------------\n",
    "# You can also decide to take the ratio between WSS and BSS to choose the perfect k\n",
    "# --------------------------\n",
    "\n",
    "w = []\n",
    "b = []\n",
    "totss = np.sum((X - X.mean(axis=0))**2)\n",
    "for k_val in range(1, 11):\n",
    "    km = KMeans(n_clusters=k_val, random_state=42).fit(X)\n",
    "    withinss = km.inertia_\n",
    "    between_ss = totss - withinss\n",
    "    w.append(withinss)\n",
    "    b.append(between_ss)\n",
    "ratio = np.array(w) / (np.array(w) + np.array(b))\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(range(1, 11), ratio, marker='o', linewidth=2)\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Within / Total variability\")\n",
    "plt.title(\"Choice of k using variability ratio\")\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------\n",
    "# K-means with standardization\n",
    "# non sempre necessario, se dati hanno different scale, allora applicala\n",
    "# ------------------------------\n",
    "\n",
    "\n",
    "scaler = StandardScaler() # this is the function to standardize\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "kmeans_scaled = KMeans(n_clusters=3, random_state=42, n_init=10) # applied to data standardized. Best init in sense of WSS (inertia)\n",
    "clusters_scaled = kmeans_scaled.fit_predict(X_scaled)\n",
    "\n",
    "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=clusters_scaled, cmap='tab10', edgecolors='k')\n",
    "plt.title(\"K-Means With Standardization\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# K-means with PCA\n",
    "# no sicurezza that this improve kmeans. might be harmful or helpful.\n",
    "# ------------------------------\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_3D_scaled = scaler.fit_transform(X) # x is 3D\n",
    "\n",
    "pca_1d = PCA(n_components=1, random_state=42)\n",
    "X_1D = pca_1d.fit_transform(X_3D_scaled)\n",
    "\n",
    "kmeans_1d = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "labels_1d = kmeans_1d.fit_predict(X_1D)\n",
    "\n",
    "# contingency table\n",
    "cont_1d = pd.crosstab(pd.Series(y_true, name='True'), pd.Series(labels_1d, name='K-Means_1D'))\n",
    "print(\"Contingency Table - After PCA to 1D:\")\n",
    "print(cont_1d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_iris' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# GMM (Gaussian Mixture model)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# another clustering method\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# assume che vi sia una multivariate gaussian distribution of data\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# tells probability that a points is of a specific cluster (gives a probability distribution)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m iris_data \u001b[38;5;241m=\u001b[39m \u001b[43mload_iris\u001b[49m()\n\u001b[1;32m      9\u001b[0m iris4 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(iris_data\u001b[38;5;241m.\u001b[39mdata, columns\u001b[38;5;241m=\u001b[39miris_data\u001b[38;5;241m.\u001b[39mfeature_names)\n\u001b[1;32m     10\u001b[0m iris \u001b[38;5;241m=\u001b[39m iris4\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_iris' is not defined"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# GMM (Gaussian Mixture model)\n",
    "# another clustering method\n",
    "# assume che vi sia una multivariate gaussian distribution of data\n",
    "# tells probability that a points is of a specific cluster (gives a probability distribution)\n",
    "# ------------------------------\n",
    "\n",
    "iris_data = load_iris()\n",
    "iris4 = pd.DataFrame(iris_data.data, columns=iris_data.feature_names)\n",
    "iris = iris4.copy()\n",
    "\n",
    "\n",
    "\n",
    "gmm = GaussianMixture(n_components=3, covariance_type='full', random_state=42)#\n",
    "# Input params:\n",
    "# n_components=1\n",
    "# covariance_type='full' # {‘full’, ‘tied’, ‘diag’, ‘spherical’}\n",
    "# tol=0.001\n",
    "# reg_covar=1e-06 # Non-negative regularization added to the diagonal of covariance.\n",
    "# max_iter=100\n",
    "# n_init=1\n",
    "# init_params='kmeans', \n",
    "# weights_init=None, \n",
    "# means_init=None, \n",
    "# precisions_init=None, \n",
    "# random_state=None, \n",
    "# warm_start=False, # If ‘warm_start’ is True, the solution of the last fitting is used as initialization for the next call of fit(). \n",
    "# verbose=0, \n",
    "# verbose_interval=10\n",
    "\n",
    "# Other attributes:\n",
    "# weights_ : array-like of shape (n_components,)\n",
    "# means_ : array-like of shape (n_components, n_features)\n",
    "# covariances_ : array-like, The covariance of each mixture component.\n",
    "# precisions_ : array-like. The precision matrices for each component in the mixture. A precision matrix is the inverse of a covariance matrix.\n",
    "# converged_ : true or false, indica convergenza raggiunta o meno\n",
    "\n",
    "# Methods:\n",
    "# aic(x), with x = array of shape (n_samples, n_dimensions)\n",
    "# bic(x)\n",
    "# fit_predict(x)\n",
    "# get_params()\n",
    "# score(x) # Compute the per-sample average log-likelihood of the given data X.\n",
    "# score_samples(x) # Compute the log-likelihood of each sample.\n",
    "gmm.fit(iris)\n",
    "\n",
    "clusters = gmm.predict(iris)\n",
    "probabilities = gmm.predict_proba(iris)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Utilities functions\n",
    "\n",
    "def plot_gmm(X, model, ax, title):\n",
    "    \"\"\"Plot GMM clustering results with covariance ellipses.\"\"\"\n",
    "    y_prob = model.predict_proba(X)  # Get probabilities\n",
    "    y_pred = model.predict(X)  # Get hard cluster assignments\n",
    "    max_prob = y_prob.max(axis=1)  # Take the highest probability per point\n",
    "\n",
    "    # Normalize alpha between 0 and 1 (probabilities)\n",
    "    norm = Normalize(vmin=0, vmax=1)\n",
    "    alpha_values = norm(max_prob)  # Normalize alpha\n",
    "\n",
    "    # Dynamically generate cluster colors\n",
    "    num_clusters = model.n_components\n",
    "    cluster_cmap = cm.get_cmap('tab10', num_clusters)  # Ensure unique colors\n",
    "    colors = np.array([cluster_cmap(i) for i in y_pred])  # Assign colors based on cluster\n",
    "    colors[:, -1] = alpha_values  # Set alpha transparency in RGBA\n",
    "\n",
    "    # Scatter plot\n",
    "    ax.scatter(X[:, 0], X[:, 1], s=50, color=colors)\n",
    "    ax.scatter(model.means_[:, 0], model.means_[:, 1], marker='*', s=200, c='black', edgecolors='white', linewidth=2)\n",
    "\n",
    "    # Plot covariance ellipses\n",
    "    for i, (mean, cov) in enumerate(zip(model.means_, model.covariances_)):\n",
    "        plot_covariance_ellipse(ax, mean, cov, 'black')\n",
    "\n",
    "    ax.set_title(title)\n",
    "\n",
    "    return ax\n",
    "\n",
    "def plot_covariance_ellipse(ax, mean, cov, color):\n",
    "    \"\"\"Plot a Gaussian covariance ellipse.\"\"\"\n",
    "    if cov.shape == (2, 2):  # Full covariance\n",
    "        U, S, Vt = np.linalg.svd(cov)\n",
    "        angle = np.degrees(np.arctan2(U[1, 0], U[0, 0]))\n",
    "        width, height = 2 * np.sqrt(S)  # 2 standard deviations\n",
    "    else:  # Diagonal covariance\n",
    "        angle = 0\n",
    "        width, height = 2 * np.sqrt(cov)\n",
    "\n",
    "    ellipse = Ellipse(mean, width, height, angle=angle, edgecolor=color, facecolor='none', linestyle='--', linewidth=2)\n",
    "    ax.add_patch(ellipse)\n",
    "\n",
    "\n",
    "\n",
    "# ARI (Adjusted Rand Index)\n",
    "# particularly useful to evaluated clusters with a ground truth table\n",
    "# ARI = 1 (perfect match), ARI = 0 (random assignment), ARI < 0 (rare but worse than random)\n",
    "\n",
    "\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "true_labels_iris = iris.target\n",
    "\n",
    "kmeans_iris = KMeans(n_clusters=3, random_state=42)\n",
    "predicted_labels_kmeans = kmeans_iris.fit_predict(X_iris)\n",
    "\n",
    "gmm_iris = GaussianMixture(n_components=3, random_state=42)\n",
    "predicted_labels_gmm = gmm_iris.fit_predict(X_iris)\n",
    "\n",
    "\n",
    "ari_kmeans = adjusted_rand_score(true_labels_iris, predicted_labels_kmeans) # Score for kmeans\n",
    "ari_gmm = adjusted_rand_score(true_labels_iris, predicted_labels_gmm)       # Score for GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNHD4K4sWBxo"
   },
   "source": [
    "# Lab5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8mOeIBQuWHyO"
   },
   "outputs": [],
   "source": [
    "# From lab 5: Linear Discriminant analysis and init for classification method\n",
    "# Supervised learning: classification\n",
    "\n",
    "from scipy.stats import shapiro, bartlett, f_oneway, norm\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# ------------------------------\n",
    "# Shapiro test for normality\n",
    "# p-value is our value that decide if rejected the H0\n",
    "# ------------------------------\n",
    "\n",
    "stat_A, pval_A = shapiro(X)\n",
    "stat_B, pval_B = shapiro(Q)\n",
    "\n",
    "print(\"Shapiro test group A:\", stat_A, pval_A) # p-value < 0.05 H_o rejected. Data not normal\n",
    "print(\"Shapiro test group B:\", stat_B, pval_B)\n",
    "\n",
    "# Bartlett test for equality of variance (check for LDA)\n",
    "bart_stat, bart_pval = bartlett(X, Q)\n",
    "print(\"Bartlett test: statistic =\", bart_stat, \"p-value =\", bart_pval)\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# LDA (QDA is more complex)\n",
    "# It finds a linear boundary that best separates the classes by maximizing the ratio of between-class variance to within-class variance.\n",
    "# It assumes each class follows a Gaussian distribution with the same covariance matrix but different means.\n",
    "# It can also estimate posterior probabilities for each class, given input features.\n",
    "\n",
    "# Priors: prior probability of each class before seeing data.\n",
    "# - Implicit (default): estimated from training data frequency.\n",
    "# - Explicit: manually specified to reflect prior knowledge.\n",
    "# ------------------------------\n",
    "\n",
    "# implicitly set the priors (Priors are the prior probabilities of each class before observing any data (your belief about how likely each class is, a priori).)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis() # methods calling obj:\n",
    "# coef_ : ndarray of shape (n_features,) or (n_classes, n_features). Are the Weight vector(s).\n",
    "# intercept_ : ndarray of shape (n_classes,)\n",
    "# covariance_ : array-like of shape (n_features, n_features)\n",
    "# predict_log_proba()\n",
    "lda.fit(X, y)\n",
    "\n",
    "# Calculation for Posterior probability for x=0: (i.e. find the probability fixed x)\n",
    "# Posterior for a grid of x\n",
    "xgrid = np.linspace(-10, 35, 200).reshape(-1, 1) # you can also decide the values to know prob, setting this [[val0], [val1]]\n",
    "post_grid = lda.predict_proba(xgrid) # it predicts per each value, the probabilities to belonging to specific final class\n",
    "postA_skl = post_grid[:,0] # all probs for class 0\n",
    "postB_skl = post_grid[:,1]\n",
    "\n",
    "# by, in a single point what happend? ex for x = 0\n",
    "x0_val = 0.0\n",
    "posterior0 = lda.predict_proba([[x0_val]])[0] # predict_probA is the prediction for all the classes. \n",
    "postA_x0, postB_x0 = posterior0  # two classes (A, B)\n",
    "print(\"Posterior at x=0:\", posterior0)\n",
    "print(\"Class assigned at x=0:\", lda.predict([[x0_val]])) # usign predict method to access the class prediction\n",
    "\n",
    "\n",
    "# explicitly set the priors, if you do not want to estimate them from the data (cosa comunque che può risultare sbagliata se dati non sono rappresentativi della popolazione)\n",
    "\n",
    "lda_1 = LinearDiscriminantAnalysis(priors=[0.95, 0.05]) # distribution of classes\n",
    "lda_1.fit(X, y)\n",
    "\n",
    "\n",
    "# Print utilities\n",
    "print(\"Coefficients of linear discriminants:\\n\", lda_1.coef_)\n",
    "print(\"Intercepts:\\n\", lda_1.intercept_)\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Confusion matrix\n",
    "# ------------------------------\n",
    "\n",
    "y_pred = lda_1.predict(X)\n",
    "conf_mat = confusion_matrix(y_real, y_pred)\n",
    "print(conf_mat)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=y_names, yticklabels=y_names)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix - Iris LDA\")\n",
    "plt.show()\n",
    "\n",
    "tp, fn, fp, tn = conf_mat.ravel() # Extract False Positives (FP) and False Negatives (FN)\n",
    "aper = p_true_c * (fn / (tp + fn)) + p_false_c * (fp / (fp + tn))\n",
    "print(\"\\nApparent Error Rate (APER): {:.4f}\".format(aper))\n",
    "\n",
    "# ------------------------------\n",
    "# APER (apparent error rate - proportion of misclassified samples)\n",
    "# ------------------------------\n",
    "\n",
    "n_samples = len(y)\n",
    "misclassified = (y_pred != y).sum()\n",
    "APER = misclassified / n_samples\n",
    "print(\"APER =\", APER)\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Other possible metrics\n",
    "# ------------------------------\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred) # percentage of point correctly classified\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# QDA (Quadratic Discriminant analysis)\n",
    "# variances different\n",
    "# ------------------------------\n",
    "\n",
    "qda_iris = QuadraticDiscriminantAnalysis()\n",
    "qda_iris.fit(X_iris, y)\n",
    "\n",
    "y_pred_qda = qda_iris.predict(X_iris)\n",
    "conf_mat_qda = pd.crosstab(pd.Series(y, name='True'),\n",
    "                           pd.Series(y_pred_qda, name='Predicted'))\n",
    "print(conf_mat_qda)\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Plots for QDA and LDA\n",
    "# ------------------------------\n",
    "def plot_lda_partition(model, X, y, class_labels=None, title=\"LDA Partition\"):\n",
    "  x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "  y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "  xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                        np.linspace(y_min, y_max, 200))\n",
    "  grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "  unique_classes = np.unique(y)\n",
    "  n_classes = len(unique_classes)\n",
    "  cmap = plt.get_cmap(\"brg\", n_classes)\n",
    "\n",
    "  class_pred = model.predict(grid_points)\n",
    "\n",
    "  plt.figure()\n",
    "  plt.scatter(X[:,0], X[:,1], c=y, cmap='brg', s=30)\n",
    "  plt.title(\"Iris LDA Partition\")\n",
    "  # Now let's draw boundaries where the predicted class changes:\n",
    "  class_pred_matrix = class_pred.reshape(xx.shape)\n",
    "  # We'll plot the contour lines between classes:\n",
    "  # e.g., any place that transitions from class i to j is a boundary.\n",
    "  plt.contour(xx, yy, class_pred_matrix,\n",
    "              colors='k', linestyles='--')\n",
    "\n",
    "  # Mark class means (model.means_ shape: [n_classes, n_features])\n",
    "  means = model.means_\n",
    "  plt.scatter(means[:,0], means[:,1], marker='x',\n",
    "              c=range(len(means)), cmap='brg', s=100, linewidths=2)\n",
    "\n",
    "  if class_labels is None:\n",
    "      class_labels = [f\"Class {cls}\" for cls in unique_classes]  # Default labels if not provided\n",
    "\n",
    "  handles = [mpatches.Patch(color=cmap(i), label=class_labels[i]) for i in range(n_classes)]\n",
    "  plt.legend(handles=handles, loc='upper right')\n",
    "\n",
    "  plt.xlabel(\"Sepal.Length\")\n",
    "  plt.ylabel(\"Sepal.Width\")\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def plot_qda_partition(model, X, y, class_labels=None, title=\"QDA Partition\", cmap=None):\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                         np.linspace(y_min, y_max, 200))\n",
    "    grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "    class_pred = model.predict(grid_points)\n",
    "    if isinstance(class_pred[0], str):\n",
    "      class_pred = np.array([np.where(class_labels == i) for i in class_pred])\n",
    "    class_pred_matrix = class_pred.reshape(xx.shape)\n",
    "\n",
    "    unique_classes = np.unique(y)\n",
    "    n_classes = len(unique_classes)\n",
    "\n",
    "    cmap = plt.get_cmap(\"brg\", n_classes)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(X[:,0], X[:,1], c=y, cmap=cmap, s=30)\n",
    "    plt.title(title)\n",
    "    plt.contour(xx, yy, class_pred_matrix,\n",
    "                colors='k', linestyles='--')\n",
    "\n",
    "    # Mark class means\n",
    "    means = model.means_\n",
    "    plt.scatter(means[:,0], means[:,1], marker='x',\n",
    "                c=range(len(means)), cmap=cmap, s=100, linewidths=2)\n",
    "\n",
    "    if class_labels is None:\n",
    "        class_labels = [f\"Class {cls}\" for cls in unique_classes]  # Default labels if not provided\n",
    "\n",
    "    handles = [mpatches.Patch(color=cmap(i), label=class_labels[i]) for i in range(n_classes)]\n",
    "    plt.legend(handles=handles, loc='upper right')\n",
    "\n",
    "    plt.xlabel(\"Sepal.Length\")\n",
    "    plt.ylabel(\"Sepal.Width\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Cost-sensitive classification\n",
    "# Using formula with costs of lab 5\n",
    "# Useful when our data is not representative of the population\n",
    "# ------------------------------\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "# init dataset:\n",
    "true_df  = pd.read_table(\"moneytrue.txt\", sep=\" \")   # columns e.g. V1, V2\n",
    "false_df = pd.read_table(\"moneyfalse.txt\", sep=\" \")  # columns e.g. V1, V2\n",
    "\n",
    "true_data  = true_df[[\"V1\",\"V2\"]].values\n",
    "false_data = false_df[[\"V1\",\"V2\"]].values\n",
    "\n",
    "banknotes = np.vstack([true_data, false_data]) \n",
    "\n",
    "# starting defining the costs\n",
    "\n",
    "c_tf = 10    # cost of accepting a false banknote\n",
    "c_ft = 0.05  # cost of rejecting a true banknote\n",
    "pf   = 0.001\n",
    "pt   = 1 - pf\n",
    "\n",
    "# Adjusted priors using the cost-design:\n",
    "den = c_tf*pf + c_ft*pt # normalization factor to keep them sum to 1\n",
    "p_true_c = pt*c_ft / den\n",
    "p_false_c = pf*c_tf / den\n",
    "prior_c = [p_true_c, p_false_c]\n",
    "\n",
    "desired_order = [\"true\", \"false\"]  # the order MUST be consisted with the order of the priors!\n",
    "y_encoded = np.array([desired_order.index(label) for label in vf])\n",
    "\n",
    "qda_bank = QuadraticDiscriminantAnalysis(priors=prior_c)\n",
    "qda_bank.fit(banknotes, y_encoded)\n",
    "\n",
    "lda_bank = LinearDiscriminantAnalysis(priors=prior_c)\n",
    "lda_bank.fit(banknotes, y_encoded)\n",
    "\n",
    "# APER for this prb\n",
    "# APER = P(true) * P(misclassified | true) + P(false) * P(misclassified | false)\n",
    "\n",
    "y_pred = qda_bank.predict(banknotes)\n",
    "conf_matrix = confusion_matrix(y_encoded, y_pred)\n",
    "\n",
    "tp, fn, fp, tn = conf_matrix.ravel() # from confusion matrix\n",
    "aper = p_true_c * (fn / (tp + fn)) + p_false_c * (fp / (fp + tn))\n",
    "\n",
    "# ------------------------------\n",
    "# Fisher discriminant analysis (also use LDA for dimensionality)\n",
    "# i.e. it not maximize the variability, but discrimination between classes\n",
    "# ------------------------------\n",
    "\n",
    "# Apply Fisher's Linear Discriminant Analysis (LDA)\n",
    "lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "X_lda = lda.fit_transform(X, y)  # Transform data into canonical coordinates\n",
    "\n",
    "# Compute the confusion matrix for model performance\n",
    "y_pred = lda.predict(X)\n",
    "conf_matrix = confusion_matrix(y, y_pred)\n",
    "APER = 1 - np.trace(conf_matrix) / np.sum(conf_matrix)\n",
    "\n",
    "x_new = np.array([[5.85, 2.90]])  # New observation\n",
    "cc_new = lda.transform(x_new)  # Project into Fisher’s space\n",
    "assigned_class = lda.predict(x_new)\n",
    "print(\"New observation classified as:\", species_names[assigned_class[0]])\n",
    "\n",
    "# Compute class means in LDA space\n",
    "class_means_lda = lda.transform(lda.means_)  # Get means in LDA space\n",
    "\n",
    "# Plot LDA Results with Connection Lines to Class Centers\n",
    "def plot_fisher_score_with_connections():\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Original Coordinate Space\n",
    "    for i, color in zip(range(3), color_species):\n",
    "        ax[0].scatter(X[y == i, 0], X[y == i, 1], c=color, label=species_names[i], alpha=0.6)\n",
    "\n",
    "    ax[0].scatter(x_new[0, 0], x_new[0, 1], c='gold', marker='X', s=100, label=\"New Point\")\n",
    "    ax[0].set_xlabel(\"Sepal Length\")\n",
    "    ax[0].set_ylabel(\"Sepal Width\")\n",
    "    ax[0].set_title(\"Original Feature Space\")\n",
    "    ax[0].legend()\n",
    "\n",
    "    # Canonical Coordinate Space (LDA Projection)\n",
    "    for i, color in zip(range(3), color_species):\n",
    "        ax[1].scatter(X_lda[y == i, 0], X_lda[y == i, 1], c=color, label=species_names[i], alpha=0.6)\n",
    "\n",
    "    ax[1].scatter(cc_new[0, 0], cc_new[0, 1], c='gold', marker='X', s=100, label=\"New Point\")\n",
    "\n",
    "    # Connect new observation to class means\n",
    "    for mean, color in zip(class_means_lda, color_species):\n",
    "        ax[1].scatter(mean[0], mean[1], c=color, marker=\"X\", s=100, edgecolors=\"black\", label=f\"Mean {color}\")\n",
    "        ax[1].plot([cc_new[0, 0], mean[0]], [cc_new[0, 1], mean[1]], color=color, linestyle=\"dashed\")\n",
    "\n",
    "    ax[1].set_xlabel(\"First Canonical Coordinate\")\n",
    "    ax[1].set_ylabel(\"Second Canonical Coordinate\")\n",
    "    ax[1].set_title(\"Canonical Coordinates (LDA Projection)\")\n",
    "    ax[1].legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_fisher_score_with_connections()\n",
    "\n",
    "\n",
    "# Fisher directions (discriminant vectors) (come PCA, ma tra loro non ortogonali) \n",
    "a1, a2 = lda.scalings_[:, 0], lda.scalings_[:, 1]\n",
    "\n",
    "# Normalize Fisher directions for visualization\n",
    "a1 /= np.linalg.norm(a1)\n",
    "a2 /= np.linalg.norm(a2) # this is just how things are done\n",
    "\n",
    "# Compute projections onto Fisher directions in the original space\n",
    "proj_a1 = np.outer(X_iris @ a1, a1) / np.sum(a1 ** 2)\n",
    "proj_a2 = np.outer(X_iris @ a2, a2) / np.sum(a2 ** 2)\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# K-Neareast Neighbour classification method\n",
    "# K-Nearest Neighbors (KNN) is a classification algorithm that assigns a label to a new data point based on the majority class among its k closest training examples.\n",
    "# It uses a distance metric (e.g., Euclidean) to find neighbors and does not build an explicit model before prediction (lazy learning).\n",
    "# Choosing the right k is crucial: small k can overfit, large k can underfit.\n",
    "# ------------------------------\n",
    "# decision boundary is whatever\n",
    "# drowback, this is a non parametric model, so you have to carry everytimes all datas. Little bit heavy\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # Using 5 neighbors\n",
    "knn.fit(X_iris, y)\n",
    "\n",
    "# Create a mesh grid for decision boundary\n",
    "x_min, x_max = X_iris[:, 0].min() - 0.1, X_iris[:, 0].max() + 0.1\n",
    "y_min, y_max = X_iris[:, 1].min() - 0.1, X_iris[:, 1].max() + 0.1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                     np.linspace(y_min, y_max, 200))\n",
    "\n",
    "# Predict the class for each point in the grid\n",
    "Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "y_pred = knn.predict(X_iris)\n",
    "conf_matrix = confusion_matrix(y, y_pred)\n",
    "\n",
    "\n",
    "# Compute APER (Apparent Error Rate)\n",
    "aper = 1 - accuracy_score(y, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "# plot\n",
    "\n",
    "# Plot the decision boundary\n",
    "plt.figure()\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap='brg')\n",
    "\n",
    "# Plot the data points\n",
    "plt.scatter(banknotes[:, 0], banknotes[:, 1], c=y_encoded, cmap='brg', edgecolor='k', s=30)\n",
    "\n",
    "# Legend for species\n",
    "handles = [\n",
    "    mpatches.Patch(color=plt.get_cmap(\"brg\", 2)(0), label='True'),\n",
    "    mpatches.Patch(color=plt.get_cmap(\"brg\", 2)(1), label='False')\n",
    "]\n",
    "plt.legend(handles=handles, loc='upper right')\n",
    "\n",
    "# Labels and title\n",
    "plt.title(\"KNN Classification of banknotes\")\n",
    "plt.xlabel(\"V1\")\n",
    "plt.ylabel(\"V2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RckyGViWWJJO"
   },
   "source": [
    "# Lab6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TIf7ZszWTxxH"
   },
   "outputs": [],
   "source": [
    "# From lab 6: Regression\n",
    "\n",
    "# ------------------------------\n",
    "# Simple linear regression\n",
    "# predict a real number\n",
    "# ------------------------------\n",
    "\n",
    "df = pd.read_csv('file_name.csv')\n",
    "X = df['feature1'].values.reshape(-1,1)  # Independent variables\n",
    "y = df['target']  # Target variable\n",
    "\n",
    "# Fit a linear regression model using sm\n",
    "\n",
    "X_const = sm.add_constant(X) # add constant term for intercept\n",
    "model = sm.OLS(y, X_const) # ordinary least squared, simplest method \n",
    "results = model.fit()\n",
    "print(results.summary())\n",
    "\n",
    "# Methods for model:\n",
    "coef = logit_model.params # Coefficienti per \n",
    "conf = logit_model.conf_int() # confidence interval for each variable (col) \n",
    "\n",
    "# Get the real predictions\n",
    "y_pred = results.predict(X_const)\n",
    "\n",
    "# Get confidence interval and prediction interval for each samples\n",
    "preddd = results.get_prediction(X_const)\n",
    "summary_frame = preddd.summary_frame(alpha=0.5) # tunable alpha for incertezza\n",
    "\n",
    "# Prediction metrics\n",
    "\n",
    "r2 = r2_score(y,y_pred)\n",
    "mse = mean_squared_error(y,y_pred)\n",
    "\n",
    "print(f'R2: {r2:.4f}')\n",
    "print(f'MSE: {mse:.4f}')\n",
    "\n",
    "# plot of linear\n",
    "X_plot = np.arange(np.min(X),np.max(X),0.1).reshape(-1,1)\n",
    "X_plot = sm.add_constant(X_plot)\n",
    "y_plot = results.predict(X_plot)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=\"ejection_fraction\", y=\"bmi\", palette=\"muted\", data=df)\n",
    "plt.plot(X_plot[:,1], y_plot, color='red')\n",
    "plt.xlabel(\"Ejection Fraction\")\n",
    "plt.ylabel(\"BMI\")\n",
    "plt.title(\"BMI vs Ejection Fraction with Regression Line\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is $$ bmi = \\beta_0 + \\beta_1 \\cdot ef + \\epsilon $$\n",
    "\n",
    "Assumptions: $\\epsilon$ is assumed to be with mean 0 and variance $\\sigma^2$, i.e the errors are normally distributed. The model assumes that the relationship between the predictor and the response variable is linear. The model also assumes that the errors are independent and identically distributed (i.i.d.). (See in the references the OLS assumptions). The model assumed also that there is no multicollinearity among the predictor variables. \n",
    "\n",
    "Note that you have to consider a large number of samples (enough for central limit theorem).\n",
    "\n",
    "On the summary there are a lot of different metrics, we can try to make a simple list:\n",
    "\n",
    "## 📈 Model Fit Statistics\n",
    "\n",
    "| **Statistic** | **Description** |\n",
    "|---------------|-----------------|\n",
    "| `R-squared` | Coefficient of determination: proportion of variance in the dependent variable explained by the model. Value here: $0.283$. Percentage of variability that my model will explain|\n",
    "| `Adj. R-squared` | Adjusted R², which accounts for the number of predictors. Slightly penalizes adding irrelevant variables. More correct if there are more variable than 2 |\n",
    "| `F-statistic` | Tests whether the model explains a significant amount of variance in the dependent variable. |\n",
    "| `Prob (F-statistic)` | p-value of the F-test. A small value (e.g., $3.06 \\times 10^{-23}$) suggests the model is statistically significant. |\n",
    "| `Log-Likelihood` | Measure of the model’s likelihood. Higher (less negative) is better. |\n",
    "| `AIC` | Akaike Information Criterion. Penalizes model complexity. Lower is better. |\n",
    "| `BIC` | Bayesian Information Criterion. Similar to AIC but more heavily penalizes complexity. Lower is better. |\n",
    "\n",
    "---\n",
    "\n",
    "## 🔢 Coefficient Table\n",
    "\n",
    "The table below summarizes the estimates of the regression coefficients:\n",
    "\n",
    "| Term | Coef | Std Err | t | P \\> \\|t\\| | [0.025, 0.975] |\n",
    "|------|------|---------|---|------------|----------------|\n",
    "| `const` | 34.5154 | 0.717 | 48.117 | 0.000 | [33.104, 35.927] |\n",
    "| `x1` | -0.1944 | 0.018 | -10.825 | 0.000 | [-0.230, -0.159] |\n",
    "\n",
    "**Descriptions:**\n",
    "\n",
    "- `coef`: Estimated coefficient.\n",
    "- `std err`: Standard error of the estimate.\n",
    "- `t`: t-statistic for the hypothesis test $H_0: \\beta = 0$.\n",
    "- `P>|t|`: p-value for the t-test. A small p-value indicates statistical significance. If some value greater than 0.05, a problem with that variable\n",
    "- `[0.025, 0.975]`: 95% confidence interval for the coefficient.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧪 Residual Diagnostics\n",
    "\n",
    "| **Element** | **Description** |\n",
    "|-------------|-----------------|\n",
    "| `Omnibus` | Omnibus test statistic for normality of residuals. |\n",
    "| `Prob(Omnibus)` | p-value for the Omnibus test. Low value indicates non-normal residuals. |\n",
    "| `Jarque-Bera (JB)` | Another test for normality, based on skewness and kurtosis. |\n",
    "| `Prob(JB)` | p-value of the Jarque-Bera test. |\n",
    "| `Skew` | Measures asymmetry of residual distribution. 0 = symmetric. |\n",
    "| `Kurtosis` | Measures the \"tailedness\" of residuals. Normal distribution = 3. |\n",
    "| `Durbin-Watson` | Test statistic for autocorrelation (indipendents) in residuals. Close to 2 is ideal. |\n",
    "| `Cond. No.` | Condition number. High values (e.g., > 30) may indicate multicollinearity. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Confidence/prediction intervals\n",
    "# since I obtain some coefficient, I have to get also a confidence interval\n",
    "# Confident interval do not consider epsilon\n",
    "# Prediction interval consider all model, also epsilon\n",
    "# ------------------------------\n",
    "\n",
    "X_plot = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\n",
    "X_plot_const = sm.add_constant(X_plot)\n",
    "\n",
    "predictions = results.get_prediction(X_plot_const) # is the method to obtain data predicted\n",
    "summary_frame = predictions.summary_frame(alpha=0.05)  # 95% intervals\n",
    "\n",
    "y_pred = summary_frame['mean']\n",
    "ci_lower = summary_frame['mean_ci_lower']\n",
    "ci_upper = summary_frame['mean_ci_upper']\n",
    "pi_lower = summary_frame['obs_ci_lower']\n",
    "pi_upper = summary_frame['obs_ci_upper']\n",
    "\n",
    "# calculate the prediction and confidente intervals for a specific point\n",
    "ef_point = 45\n",
    "X_new = np.array([[1, ef_point]])  # Add constant manually\n",
    "\n",
    "# Get predictions with confidence and prediction intervals\n",
    "pred_result = results.get_prediction(X_new)\n",
    "pred_summary = pred_result.summary_frame(alpha=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Multiple linear regression\n",
    "# you can have fino a p (set of variables) <= n (number of samples)\n",
    "# look at R_adj_^2, meglio di R^2\n",
    "# ------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# ------------------------------\n",
    "# VIF computation   \n",
    "# The Variance Inflation Factor (VIF) indicates how good a variable can be predicted from the others\n",
    "# VIF > 5 for a variable is problematic\n",
    "# you can see from summary at cond. No. very high\n",
    "# It is a measure for multicollinearity of the design matrix\n",
    "# ------------------------------\n",
    "\n",
    "data = X_train_2\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = data.columns\n",
    "\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(data.values, i) for i in range(data.shape[1])]\n",
    "\n",
    "print(vif_data)\n",
    "\n",
    "# print the heatmap of correlation matrix\n",
    "sns.heatmap(df[X_var_numerics].corr(), cmap=\"Blues\",annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Standardized coefficients\n",
    "# Standardized coefficients are useful to compare the relative importance of predictors in a regression model.\n",
    "# They are computed by standardizing both the dependent and independent variables before fitting the model.\n",
    "# ------------------------------\n",
    "variables = ['ejection_fraction', 'serum_creatinine', 'time']\n",
    "\n",
    "X_train_2 = X_train[variables]\n",
    "X_test_2 = X_test[variables]\n",
    "\n",
    "scaler = StandardScaler() # you have to standardize your variable (only input vars). Applicalo solo alle numerical variables.\n",
    "X_train_2_scaled = pd.DataFrame(scaler.fit_transform(X_train_2), columns=X_train_2.columns, index=X_train_2.index)\n",
    "X_test_2_scaled = pd.DataFrame(scaler.transform(X_test_2), columns=X_test_2.columns, index=X_test_2.index) # transform because you are using the sigma and mu of the training set\n",
    "\n",
    "X_train_2_scaled = sm.add_constant(X_train_2_scaled)\n",
    "X_test_2_scaled = sm.add_constant(X_test_2_scaled)\n",
    "\n",
    "# Fit the model on standardized training data\n",
    "# After standardization, you can compare all statistics from the result.description. Il significato dei beta è diverso, non come senza stardardizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# ------------------------------\n",
    "# Polynomial features\n",
    "# Polynomial features allow you to create interaction terms and polynomial terms of the original features.\n",
    "# per essere linear model, basta che ci siano i beta. I coefficienti possono essere quadratic, cubic...\n",
    "# R_adj very important with a lot of vars\n",
    "# ------------------------------\n",
    "\n",
    "variables = ['ejection_fraction']\n",
    "\n",
    "X_train_6 = X_train[variables]\n",
    "X_test_6 = X_test[variables]\n",
    "\n",
    "# computing the new var squared\n",
    "polynomial2 = PolynomialFeatures(degree=2, include_bias=True) # degree 2 is the elevation to the power \n",
    "X_train_6 = polynomial2.fit_transform(X_train_6) # nuova versione con il termine alla seconda\n",
    "X_test_6 = polynomial2.fit_transform(X_test_6)  # nuova versione ...\n",
    "# se aggiungo due termini al quadrato, dovrò anche aggiungere il termine di correlazione fra loro\n",
    "# per fortuna fa tutto polynomialFeatures\n",
    "\n",
    "\n",
    "\n",
    "# standardize the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# skip the first column (constant term) se standardizzi, SEMPRE\n",
    "# Scale everything except the constant term (column index 0)\n",
    "X_train_6[:, 1:] = scaler.fit_transform(X_train_6[:, 1:]) \n",
    "# Apply the same transformation to the test set\n",
    "X_test_6[:, 1:] = scaler.transform(X_test_6[:, 1:])\n",
    "\n",
    "# Convert to DataFrame, maintaining the column names\n",
    "cols = ['const', 'ef', 'ef^2']\n",
    "# cols = polynomial2.get_feature_names_out() # automatic get names\n",
    "X_train_6 = pd.DataFrame(X_train_6, columns=cols, index=train_index)\n",
    "X_test_6 = pd.DataFrame(X_test_6, columns=cols, index=test_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# ------------------------------\n",
    "# Categorical features\n",
    "# Categorical features can be included in regression models using one-hot encoding or dummy variables.\n",
    "# One-hot encoding creates binary columns for each category, while dummy variables create k-1 columns for k categories.\n",
    "# ------------------------------\n",
    "\n",
    "# Data preparation\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)  # The specific format to encode your data. drop=first vuol dire che il primo valore viene eliminato. sparse_output=False vuol dire che non viene restituita una matrice sparsa, ma una matrice densa\n",
    "encoded_feature = encoder.fit_transform(df[X_categorical_vars_names])\n",
    "\n",
    "df_encoded = pd.DataFrame(encoded_feature, columns=encoder.get_feature_names_out(X_categorical_vars_names))\n",
    "\n",
    "df_encoded = pd.concat([df.drop(X_categorical_vars_names, axis=1), df_encoded], axis=1)\n",
    "\n",
    "\n",
    "# train data with categorical features and numerical features\n",
    "X_train_9_cat = df_encoded.loc[train_index, cat_variables]\n",
    "X_test_9_cat = df_encoded.loc[test_index, cat_variables]\n",
    "\n",
    "# Concatenate the polynomial features with the one-hot encoded categorical variable\n",
    "X_train_9 = np.concatenate([X_train_9_num, X_train_9_cat], axis=1) # axis = 1 means concatenate along columns\n",
    "X_test_9 = np.concatenate([X_test_9_num, X_test_9_cat], axis=1)\n",
    "\n",
    "cols = num_variables + cat_variables\n",
    "X_train_9 = pd.DataFrame(X_train_9, index=train_index, columns=cols)\n",
    "X_test_9 = pd.DataFrame(X_test_9, index=test_index, columns=cols)\n",
    "\n",
    "X_train_9 = sm.add_constant(X_train_9) # to represent beta0\n",
    "X_test_9 = sm.add_constant(X_test_9)\n",
    "\n",
    "# fit the model on training data\n",
    "model = sm.OLS(y_train, X_train_9)\n",
    "results = model.fit()\n",
    "print(results.summary())\n",
    "\n",
    "# predictions\n",
    "y_pred = results.predict(X_test_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumptions:\n",
    "\n",
    "1. There is a linear relationship between the predictors and the response. Ovvero E[$\\epsilon_i$] = 0\n",
    "2. $\\epsilon_i$ (residuals) are indipendent\n",
    "3. $Var(\\epsilon_i) = \\sigma^2 \\quad \\forall i $ (homoschedasticity)\n",
    "\n",
    "and for inference:\n",
    "\n",
    "4. $\\epsilon_i \\sim N(0,\\sigma^2) \\quad \\forall i$ (normality) --- or at least large $n$ (sample size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Diagnostics : Check for OLS assumptions (for linear regression)\n",
    "# ------------------------------\n",
    "\n",
    "# check for indipendence\n",
    "\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "# The values of its test statistics are between 0 and 4.\n",
    "# Values near 2 indicates no autocorrelation (independence), smaller values indicate positive autocorrelation, higher values negative autocorrelation\n",
    "durbin_watson(results.resid) # result preso dall'sm.OLS\n",
    "\n",
    "\n",
    "# check for homoscedasticity\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan # H0 : residual are homoscedastic\n",
    "\n",
    "bp_test = het_breuschpagan(results.resid, X_train_9)\n",
    "print(f'p-value: {bp_test[1]}') # test di ipotesi. Se è < 0.05, reject the null hypothesis of homoscedasticity\n",
    "\n",
    "\n",
    "# check for linearity (controlla dal grafico se più o meno segue linea nera)\n",
    "fitted_vals = results.fittedvalues # values\n",
    "residuals = results.resid # plot them\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.residplot(x=fitted_vals, y=residuals, lowess=True,\n",
    "              line_kws={'color': 'red', 'lw': 1.5})  # Add a smooth trendline\n",
    "\n",
    "plt.axhline(0, color='black', linestyle='--', lw=2)  # Horizontal line at 0\n",
    "plt.xlabel('Fitted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals vs Fitted Values for Linearity & Homoscedasticity Check')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Gaussianity\n",
    "print(f'Jacques-Bera test p-value: {results.diagn[\"jbpv\"]:.4f}') # H0: data are normally distributed\n",
    "\n",
    "sw = stats.shapiro(results.resid).pvalue\n",
    "print(f'Shapiro-Wilk test p-value: {sw:.4f}') \n",
    "# the data are not gaussian. if <0.05, reject the null hypothesis of gaussianity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Check for outliers and data influence (influence plot using sm)\n",
    "# Cook's distance is a measure of the influence of a data point on the fitted model. \n",
    "# leverages are point with unusual value, out the original distribution of the points\n",
    "# ------------------------------\n",
    "\n",
    "# Usando il plot\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sm.graphics.influence_plot(results, criterion=\"cooks\", ax=ax)\n",
    "\n",
    "# usando numeri\n",
    "influence = results.get_influence() # this is how to acces to the influence measures\n",
    "influence_df = influence.summary_frame()[['cooks_d', 'student_resid', 'hat_diag']]\n",
    "influence_df = influence_df.rename(columns={'hat_diag': 'leverage'}).sort_values(by='cooks_d', ascending=False)\n",
    "influence_df # risultato finale\n",
    "\n",
    "# NB: if a point has got NaN cooks_distance -> all linear model depends on him, so discard it\n",
    "\n",
    "cooks_d = influence.cooks_distance[0]\n",
    "leverage = influence.hat_matrix_diag\n",
    "\n",
    "# remove datas. Only remove the train datas\n",
    "to_remove = [9]\n",
    "X_train_11 = X_train_5.drop(to_remove)\n",
    "y_train_11 = y_train.drop(to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Binary logistic regression (is a classification problem, supervised classification)\n",
    "# used when the dependent variable is binary (0/1). Usa sigmoid to determine and a threshold\n",
    "# ------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# Fit the logistic regression model\n",
    "X_train_1 = X_train[num_vars]\n",
    "X_test_1 = X_test[num_vars]\n",
    "\n",
    "logit_model = sm.Logit(y_train, X_train_1).fit()\n",
    "\n",
    "print(logit_model.summary())\n",
    "\n",
    "# LLR p-value: is a very useful test, does the model fit better than the null model?\n",
    "# LL is the log-likelihood of the model\n",
    "# The null model is a model with no predictors, only the intercept.\n",
    "# if converge = false -> warning\n",
    "\n",
    "# predictions\n",
    "y_test_pred_prob = logit_model.predict(X_test_1)  # probabilistic output\n",
    "\n",
    "# # Convert probabilities to binary outcomes based on a threshold\n",
    "threshold = 0.5 # easiest solution. La più completa è 1 - % negativi\n",
    "y_test_pred_class = (y_test_pred_prob > threshold).astype(int) # convert vector of probs into binary\n",
    "\n",
    "\n",
    "cm =confusion_matrix(y_test, y_test_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix like:\n",
    "\n",
    "[  TN    FP  \n",
    "   FN    TP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Odds ratio\n",
    "# ------------------------------\n",
    "\n",
    "coef = logit_model.params\n",
    "odds_ratios = np.exp(coef)\n",
    "\n",
    "conf = logit_model.conf_int() # calc confidence interval\n",
    "conf.columns = ['2.5%', '97.5%']\n",
    "conf = np.exp(conf)  # Exponentiate to get ORs' CIs\n",
    "\n",
    "or_summary = pd.DataFrame({\n",
    "    \"Coefficient\": coef,\n",
    "    \"Odds Ratio\": odds_ratios,\n",
    "    \"2.5% CI OR\": conf['2.5%'],\n",
    "    \"97.5% CI OR\": conf['97.5%']\n",
    "})\n",
    "\n",
    "print(or_summary)\n",
    "\n",
    "# if the Odd Ratio is greater than 1, it means that the predictor increases the odds of the event occurring\n",
    "# if the Odd Ratio is less than 1, it means that the predictor decreases the odds of the event occurring (negative value)\n",
    "# occhio anche molto al confidence interval \n",
    "\n",
    "# plot confidence interval of odds ratio\n",
    "fig, ax = plt.subplots(figsize=(8, len(or_summary) * 0.6))\n",
    "\n",
    "ax.errorbar(or_summary['Odds Ratio Mildly Reduced'], or_summary.index,\n",
    "            xerr=[or_summary['Odds Ratio Mildly Reduced'] - or_summary['2.5% CI OR Mildly Reduced'], or_summary['97.5% CI OR Mildly Reduced'] - or_summary['Odds Ratio Mildly Reduced']],\n",
    "            fmt='o', color='darkblue', ecolor='lightgray', elinewidth=3, capsize=4)\n",
    "\n",
    "ax.axvline(1, color='red', linestyle='--')\n",
    "\n",
    "ax.set_xlabel(\"Odds Ratio (log scale) Mildly Reduced\")\n",
    "ax.set_title(\"Forest Plot of Odds Ratios for Mildly Reduced class with 95% CI\")\n",
    "ax.set_xscale(\"log\")  # Log scale for better visualization\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Metrics for binary classification\n",
    "# ------------------------------\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# ROC curve -> AUC is the area under the ROC curve, which is a measure of the model's ability to distinguish between classes.\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_pred_prob) # thresholds also from here\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f\"ROC Curve\")\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--', label=\"Chance\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve for Binary Classification\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ROC-AUC (Area Under the Curve)\n",
    "# ottimo vicino a 1\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_test_pred_prob) # ci sono anche altre metriche come il weighted, guarda sotto\n",
    "print(f\"ROC-AUC Score on Test Set: {auc_score}\")\n",
    "\n",
    "# compute accuracy\n",
    "from sklearn.metrics import classification_report # fastest method to compute the classification report\n",
    "\n",
    "print(\"\\nClassification Report on Test Set:\")\n",
    "print(classification_report(y_test, y_test_pred_class, target_names=['Survived', 'Dead']))\n",
    "\n",
    "# specificity is the recall of negative class, what is the percentage of actual negatives that are predicted as negative\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "\n",
    "# sensitivity (or Recall or TPR) what is the percentage of actual positives that are predicted as positive\n",
    "sensitivity = tp / (tp + fn)\n",
    "print(f\"Sensitivity (Recall): {sensitivity:.4f}\")\n",
    "\n",
    "# precision percentage that are predicted as positive that are actually positive\n",
    "precision = tp / (tp + fp)\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "# false positive rate (FPR)\n",
    "fpr = fp / (fp + tn)\n",
    "print(f\"False Positive Rate (FPR): {fpr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Choice of threshold\n",
    "# ------------------------------\n",
    "\n",
    "# the proportion of negative samples in the dataset is a good threshold to use\n",
    "optimal_threshold_1 = 1 - df['DEATH_EVENT'].mean() # 1 - % of positive samples\n",
    "# model is more conservative, it will predict less positive samples, but more accurate\n",
    "# reduced false positive rate, but increased false negative rate\n",
    "# Also look at roc_curve method\n",
    "\n",
    "# compute the confusion matrix for the optimal threshold\n",
    "y_test_pred_class_optimal = (y_test_pred_prob > optimal_threshold_1).astype(int)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_class_optimal).ravel()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Multiclass logistic regression\n",
    "# ------------------------------\n",
    "\n",
    "# data preparation\n",
    "\n",
    "df['ef_cat'] = pd.cut(df['ejection_fraction'], bins=[0,40,50, 100], labels=['reduced', 'mildly reduced', 'preserved'])\n",
    "# note that: The bins parameter defines interval boundaries used to divide the continuous variable ejection_fraction into discrete categories (bins).\n",
    "# model change if you change the order of the categories. order is important.\n",
    "df_encoded = pd.get_dummies(df, columns=cat_vars, drop_first=True, dtype=int) # another way to apply one-hot encoding\n",
    "X = df_encoded[['age', 'bmi', 'serum_sodium', 'serum_creatinine', 'diabetes_1', 'sex_Male', 'smoking_1', 'high_blood_pressure_1', 'anaemia_1']]\n",
    "y = df_encoded['ef_cat']\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234, stratify=y) #STRATIFICATION WITH RESPECT TO THE TARGET CLASS\n",
    "\n",
    "model = sm.MNLogit(y_train, X_train) # the new method for multinomial logistic regression\n",
    "result = model.fit()\n",
    "\n",
    "print(result.summary())\n",
    "\n",
    "# parameters\n",
    "result.params\n",
    "np.exp(result.params).rename(columns={0: 'mildly_reduced OR', 1:'preserved OR'})\n",
    "\n",
    "# predictions\n",
    "y_test_pred_prob = result.predict(X_test) \n",
    "\n",
    "\n",
    "# Compute ROC AUC for each class (one-vs-all)\n",
    "roc_auc_scores = {}\n",
    "for i in (y_test_pred_prob.columns):\n",
    "    roc_auc = roc_auc_score(y_test == i, y_test_pred_prob.loc[:, i])  # Treat class i as positive\n",
    "    roc_auc_scores[i] = roc_auc\n",
    "\n",
    "# Output the ROC AUC scores\n",
    "for class_name, auc in roc_auc_scores.items():\n",
    "    print(f'ROC AUC for {class_name}: {auc:.2f}')\n",
    "\n",
    "\n",
    "# different modality to compute the ROC AUC\n",
    "\n",
    "y_test = y_test.map({'reduced': 0, 'mildly reduced': 1, 'preserved': 2})\n",
    "y_test_pred_prob.rename(columns={'reduced': 0, 'mildly reduced': 1, 'preserved': 2}, inplace=True)\n",
    "\n",
    "roc_auc_micro = roc_auc_score(y_test, y_test_pred_prob, average='micro', multi_class='ovr')\n",
    "print(f'Micro-average ROC AUC: {roc_auc_micro:.2f}')\n",
    "\n",
    "roc_auc_micro = roc_auc_score(y_test, y_test_pred_prob, average='macro', multi_class='ovr')\n",
    "print(f'Macro-average ROC AUC: {roc_auc_micro:.2f}')\n",
    "\n",
    "roc_auc_micro = roc_auc_score(y_test, y_test_pred_prob, average='weighted', multi_class='ovr')\n",
    "print(f'Weighted-average ROC AUC: {roc_auc_micro:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use macro when:\n",
    "\n",
    "*  You care about per-class behavior, and you want to treat all classes equally, regardless of their frequency.\n",
    "\n",
    "*  You want to evaluate model fairness across all classes, including rare or underrepresented ones.\n",
    "\n",
    "*  You're dealing with imbalanced data, and you want to make sure small classes still matter in the evaluation.\n",
    "\n",
    "*  You want to highlight weaknesses in your model’s performance on rare classes.\n",
    "\n",
    "\n",
    "\n",
    "Use micro when:\n",
    "\n",
    "*  You don't care about classes individually.\n",
    "\n",
    "* You only care about total prediction quality.\n",
    "\n",
    "* You are working with highly multilabel settings (many labels per sample).\n",
    "\n",
    "* You want one simple number for \"How many labels did I guess right?\".\n",
    "\n",
    "Use weighted when:\n",
    "\n",
    "* You do care about per-class behavior.\n",
    "\n",
    "* You want a summary that adjusts for imbalance but still thinks per-class.\n",
    "\n",
    "* You have imbalanced classes, but you still want per-class precision/recall insight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Feature selection (variable selection)\n",
    "# ------------------------------\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "numeric_vars = num_vars.copy()\n",
    "numeric_vars.remove('ejection_fraction')\n",
    "categorical_vars = cat_vars.copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Preprocessing (scaling and encoding)\n",
    "preprocessor = ColumnTransformer([ # transform list of steps \n",
    "    ('num', StandardScaler(), numeric_vars),\n",
    "    ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_vars)\n",
    "])\n",
    "\n",
    "# apply the preprocessor to the training and test data\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_test_proc = preprocessor.transform(X_test)\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "\n",
    "# metrics for feature selection\n",
    "n = len(y_test)\n",
    "def get_model_stats(y_true, y_pred, p, mse_full): # are heuristic values\n",
    "    rss = np.sum((y_true - y_pred) ** 2)\n",
    "    mse = rss / len(y_true)\n",
    "    aic = n * np.log(mse) + 2 * p\n",
    "    bic = n * np.log(mse) + p * np.log(n)\n",
    "    cp = rss / mse_full - n + 2 * p\n",
    "    return aic, bic, cp\n",
    "\n",
    "\n",
    "# fit the model with all features and compute rss, mse, aic, bic, cp\n",
    "\n",
    "ols_model = LinearRegression().fit(X_train_proc, y_train)\n",
    "train_rss_full = np.sum((y_train - ols_model.predict(X_train_proc)) ** 2)\n",
    "mse_full = train_rss_full / len(y_train)\n",
    "y_pred_ols = ols_model.predict(X_test_proc)\n",
    "aic_ols, bic_ols, cp_ols = get_model_stats(y_test, y_pred_ols, X_test_proc.shape[1] + 1, mse_full)\n",
    "\n",
    "\n",
    "# Or also with logistic regression for classification tasks\n",
    "\n",
    "logreg_full = LogisticRegression(max_iter=1000).fit(X_train_proc, y_train)\n",
    "y_pred_full = logreg_full.predict(X_test_proc)\n",
    "y_proba_full = logreg_full.predict_proba(X_test_proc)[:, 1]\n",
    "logloss_full = log_loss(y_test, y_proba_full)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Best Subset Selection (slow in time)\n",
    "# ------------------------------\n",
    "\n",
    "efs = ExhaustiveFeatureSelector(LinearRegression(), min_features=1, max_features=10, scoring='r2', cv=5) # LinearRegression is the model to be used. CV stands for cross-validation\n",
    "# every step its appplying cross-validation to the model\n",
    "efs.fit(X_train_proc, y_train)\n",
    "best_subset_idx = list(efs.best_idx_)\n",
    "model_best = LinearRegression().fit(X_train_proc[:, best_subset_idx], y_train)\n",
    "y_pred_best = model_best.predict(X_test_proc[:, best_subset_idx])\n",
    "aic_best, bic_best, cp_best = get_model_stats(y_test, y_pred_best, len(best_subset_idx) + 1, mse_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Forward Selection\n",
    "# ------------------------------\n",
    "\n",
    "# specify the model, linear regression or also LogisticRegression for classification\n",
    "sfs_forward = SequentialFeatureSelector(LinearRegression(), direction='forward', cv=5, scoring='r2')\n",
    "sfs_forward.fit(X_train_proc, y_train)\n",
    "fmask = sfs_forward.get_support()\n",
    "model_fwd = LinearRegression().fit(X_train_proc[:, fmask], y_train)\n",
    "y_pred_fwd = model_fwd.predict(X_test_proc[:, fmask])\n",
    "aic_fwd, bic_fwd, cp_fwd = get_model_stats(y_test, y_pred_fwd, sum(fmask) + 1, mse_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Backward Elimination (some times a lot number of features, so not use it. Impossible to fit the model)\n",
    "# ------------------------------\n",
    "\n",
    "sfs_backward = SequentialFeatureSelector(LinearRegression(), direction='backward', cv=5, scoring='r2')\n",
    "sfs_backward.fit(X_train_proc, y_train)\n",
    "bmask = sfs_backward.get_support()\n",
    "model_bwd = LinearRegression().fit(X_train_proc[:, bmask], y_train)\n",
    "y_pred_bwd = model_bwd.predict(X_test_proc[:, bmask])\n",
    "aic_bwd, bic_bwd, cp_bwd = get_model_stats(y_test, y_pred_bwd, sum(bmask) + 1, mse_full)\n",
    "\n",
    "\n",
    "# NOTE: IMPORTANT:\n",
    "# between those three methods, the best one is the one with the lowest AIC, BIC and CP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Cross validation\n",
    "# Cross-validation is a technique to assess how the results of a statistical analysis will generalize to an independent dataset.\n",
    "# ------------------------------\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score, KFold, LeaveOneOut\n",
    "\n",
    "\n",
    "# dataset preparation\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_vars),\n",
    "    ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_vars)\n",
    "])\n",
    "\n",
    "# Full pipeline\n",
    "pipeline = Pipeline([ # the steps of the pipeline\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Define scoring metrics\n",
    "scoring = {\n",
    "    'MSE': make_scorer(mean_squared_error),\n",
    "    'MAE': make_scorer(mean_absolute_error),\n",
    "    'R2': make_scorer(r2_score)\n",
    "}\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=123)\n",
    "\n",
    "# print metrics for each fold\n",
    "print(f\"\\n {k}-Fold Cross-Validation:\")\n",
    "kfold_results = {}\n",
    "for metric, scorer in scoring.items():\n",
    "    scores = cross_val_score(pipeline, X, y, scoring=scorer, cv=kf)\n",
    "    kfold_results[metric] = (np.mean(scores), np.std(scores))\n",
    "    print(f\"{metric}: Mean = {scores.mean():.3f}, Std = {scores.std():.3f}\")\n",
    "\n",
    "\n",
    "# Leave-One-Out Cross-Validation. Has got very large variance, because it uses only one sample for testing and the rest for training.\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# all other equal but not compute R2, is not defined for LOO\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Penalized linear regression (ridge e lasso)\n",
    "# Add a penalty to OLS. A key point is alpha (more large, more penalty)\n",
    "# ------------------------------\n",
    "from sklearn.linear_model import  Ridge, Lasso # for lasso also max_iter\n",
    "# increase the total performance of model\n",
    "\n",
    "# Define X and y\n",
    "X = df[['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes', 'high_blood_pressure',\n",
    "        'platelets', 'serum_creatinine', 'serum_sodium', 'sex', 'smoking', 'bmi', 'time',\n",
    "        'DEATH_EVENT']]\n",
    "y = df['ejection_fraction']\n",
    "\n",
    "# Feature groups\n",
    "numeric_vars = num_vars.copy()\n",
    "numeric_vars.remove('ejection_fraction')\n",
    "categorical_vars = cat_vars.copy()\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_vars), # Standard scaler is mandatory\n",
    "    ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_vars)\n",
    "])\n",
    "\n",
    "# Pipelines\n",
    "ols_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Ridge pipeline\n",
    "ridge_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', Ridge(alpha=10))  # Adjust alpha as desired\n",
    "])\n",
    "\n",
    "\n",
    "# Fit models\n",
    "ols_pipeline.fit(X, y)\n",
    "ridge_pipeline.fit(X, y)\n",
    "\n",
    "# Predictions\n",
    "y_pred_ols = ols_pipeline.predict(X)\n",
    "y_pred_ridge = ridge_pipeline.predict(X)\n",
    "\n",
    "# Feature names\n",
    "feature_names = ridge_pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "\n",
    "# Coefficients\n",
    "ols_coefs = ols_pipeline.named_steps['regressor'].coef_\n",
    "ridge_coefs = ridge_pipeline.named_steps['regressor'].coef_\n",
    "\n",
    "# Intercepts\n",
    "ols_intercept = ols_pipeline.named_steps['regressor'].intercept_\n",
    "ridge_intercept = ridge_pipeline.named_steps['regressor'].intercept_\n",
    "\n",
    "# Combine into one DataFrame\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': ['Intercept'] + list(feature_names),\n",
    "    'OLS': [ols_intercept] + list(ols_coefs),\n",
    "    'Ridge': [ridge_intercept] + list(ridge_coefs)\n",
    "})\n",
    "\n",
    "# Evaluation metrics\n",
    "def evaluate(y_true, y_pred):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    n, p = len(y_true), len(feature_names)\n",
    "    adj_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "    return {\n",
    "        'Adj R^2': adj_r2,\n",
    "        'MSE': mean_squared_error(y_true, y_pred),\n",
    "        'MAE': mean_absolute_error(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "metrics_df = pd.DataFrame([\n",
    "    {'Model': 'OLS', **evaluate(y, y_pred_ols)},\n",
    "    {'Model': 'Ridge', **evaluate(y, y_pred_ridge)}\n",
    "])\n",
    "\n",
    "# Display results\n",
    "print(\"Coefficient Comparison:\")\n",
    "print(coef_df)\n",
    "\n",
    "print(\"\\nPerformance Metrics:\")\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Use Cross validation to finetune alpha\n",
    "# ------------------------------\n",
    "\n",
    "# you can use CV for alpha selection. \n",
    "\n",
    "ridge_params = {'regressor__alpha': np.logspace(-3, 3, 50)}\n",
    "ridge_cv = GridSearchCV(ridge_pipeline, ridge_params, cv=5)\n",
    "\n",
    "# or with lasso\n",
    "\n",
    "# Lasso Pipeline with GridSearch\n",
    "lasso_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', Lasso(max_iter=10000))\n",
    "])\n",
    "\n",
    "lasso_params = {'regressor__alpha': np.logspace(-3, 3, 50)}\n",
    "lasso_cv = GridSearchCV(lasso_pipeline, lasso_params, cv=5)\n",
    "\n",
    "# Best alphas\n",
    "print(\"Best alpha for Ridge:\", ridge_cv.best_params_['regressor__alpha'])\n",
    "print(\"Best alpha for Lasso:\", lasso_cv.best_params_['regressor__alpha'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Nested Cross Validation (CV) to find the best value for alpha\n",
    "# ------------------------------\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Define model search spaces\n",
    "ridge_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', Ridge())\n",
    "])\n",
    "ridge_params = {'regressor__alpha': np.logspace(-3, 3, 50)}\n",
    "ridge_nested = GridSearchCV(ridge_pipeline, ridge_params, cv=5)\n",
    "\n",
    "lasso_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', Lasso(max_iter=10000))\n",
    "])\n",
    "lasso_params = {'regressor__alpha': np.logspace(-3, 3, 50)}\n",
    "lasso_nested = GridSearchCV(lasso_pipeline, lasso_params, cv=5)\n",
    "\n",
    "# Outer CV for nested evaluation\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate nested Ridge\n",
    "ridge_scores = cross_validate(ridge_nested, X, y, scoring=(\n",
    "    'neg_mean_squared_error', 'neg_mean_absolute_error', 'r2'), cv=outer_cv)\n",
    "\n",
    "# Evaluate nested Lasso\n",
    "lasso_scores = cross_validate(lasso_nested, X, y, scoring=(\n",
    "    'neg_mean_squared_error', 'neg_mean_absolute_error', 'r2'), cv=outer_cv)\n",
    "\n",
    "# better stratified cross-validation that regular cross-validation because it preserves the percentage of samples for each class in each fold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Cross Validation (CV) for kNN\n",
    "# ------------------------------\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Range of k to try\n",
    "k_range = range(1, 31)\n",
    "scores = []\n",
    "\n",
    "# Cross-validation to find best k\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k) # trie to keep y distribution constant among folds\n",
    "    cv_scores = cross_val_score(knn, X, y, cv=5, scoring='f1_macro')\n",
    "    scores.append(cv_scores.mean())\n",
    "\n",
    "# Best k\n",
    "best_k = k_range[np.argmax(scores)]\n",
    "print(f\"Best k: {best_k} with macro-f1: {max(scores):.4f}\")\n",
    "\n",
    "# Train final model with best k\n",
    "knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn.fit(X, y)\n",
    "\n",
    "# Optional: plot accuracy vs. k\n",
    "plt.plot(k_range, scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated Macro-F1')\n",
    "plt.title('KNN Hyperparameter Tuning')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 9\n",
    "\n",
    "Decision trees, random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Decision trees for classification\n",
    "# ------------------------------\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# parameters: max_depth\n",
    "# metrics: gini index(the most important, if not zero, the model wants to split again and go deeper with the tree)\n",
    "# also it is entropy. \n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42, test_size=0.2)\n",
    "\n",
    "# Train decision tree using all features\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=42) # max_depth is very important\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "train_acc = accuracy_score(y_train, clf.predict(X_train))\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc:.2f}\")\n",
    "print(f\"Test Accuracy:  {test_acc:.2f}\")\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "\n",
    "# plot the tree\n",
    "# Tree Visualization\n",
    "plt.figure(figsize=(16, 10))\n",
    "plot_tree(clf, feature_names=feature_names, class_names=target_names, filled=True, rounded=True)\n",
    "plt.title(\"Decision Tree Trained on All Features\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# metrics calculation\n",
    "# Gini is the most important one that define how the split is important and significant\n",
    "\n",
    "clf_gini = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=42)\n",
    "clf_entropy = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=42)\n",
    "\n",
    "clf_gini.fit(X_train, y_train)\n",
    "clf_entropy.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Gini Test Accuracy:    {accuracy_score(y_test, clf_gini.predict(X_test)):.2f}\")\n",
    "print(f\"Entropy Test Accuracy: {accuracy_score(y_test, clf_entropy.predict(X_test)):.2f}\")\n",
    "\n",
    "\n",
    "# Importance of features\n",
    "\n",
    "importances = clf.feature_importances_  # attribute of classifier\n",
    "for name, score in sorted(zip(feature_names, importances), key=lambda x: -x[1]):\n",
    "    print(f\"{name:25s}: {score:.3f}\")\n",
    "\n",
    "\n",
    "# Find the best depth for tree (depth control)\n",
    "\n",
    "depths = range(1, 11)\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for d in depths:\n",
    "    clf = DecisionTreeClassifier(max_depth=d, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_scores.append(clf.score(X_train, y_train)) # score need all model, while accuracy_score takes only two predictions\n",
    "    test_scores.append(clf.score(X_test, y_test))\n",
    "\n",
    "plt.plot(depths, train_scores, label=\"Train\")\n",
    "plt.plot(depths, test_scores, label=\"Test\")\n",
    "plt.xlabel(\"Tree Depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Decision Tree Depth vs. Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# pruning the model. Find the best alpha, that is the add of a penalty during training\n",
    "# alpha serve a bilanciare la purezza (quanto bene classifica) e semplicità (meno nodi), simile a bias variance\n",
    "\n",
    "\n",
    "path = clf.cost_complexity_pruning_path(X_train, y_train) # provides a set of alphas that are relevants\n",
    "alphas = path.ccp_alphas[:-1]  # skip last (trivial) tree\n",
    "\n",
    "for alpha in alphas:\n",
    "    clf_pruned = DecisionTreeClassifier(random_state=42, ccp_alpha=alpha)\n",
    "    clf_pruned.fit(X_train, y_train)\n",
    "    print(f\"Alpha: {alpha:.5f} | Test Accuracy: {clf_pruned.score(X_test, y_test):.3f}\")\n",
    "\n",
    "# but the best method to select alpha is via cross validation (look at the lab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Decision trees for regression (less flexible and less used)\n",
    "# ------------------------------\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# you can use RSS (instead of gini e entropy) to know how to split the classes\n",
    "\n",
    "# Separate features/target\n",
    "X = df.drop(columns='ejection_fraction')\n",
    "y = df['ejection_fraction']\n",
    "\n",
    "numeric_vars = num_vars.copy()\n",
    "numeric_vars.remove('ejection_fraction')\n",
    "categorical_vars = cat_vars.copy()\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_vars),\n",
    "    ('cat', OneHotEncoder(drop='first'), categorical_vars)\n",
    "])\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', DecisionTreeRegressor(random_state=42, max_depth=4))\n",
    "])\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit model\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Adjusted R²\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "n = len(y_test)\n",
    "p = preprocessor.fit(X_train).transform(X_train).shape[1]\n",
    "adj_r2 = 1 - ((1 - r2) * (n - 1)) / (n - p - 1)\n",
    "\n",
    "# Metrics\n",
    "mse = mean_squared_error(y_test, y_pred)    \n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"R² Score:       {r2:.3f}\")\n",
    "print(f\"Adjusted R²:    {adj_r2:.3f}\")\n",
    "print(f\"MSE:            {mse:.3f}\")\n",
    "print(f\"MAE:            {mae:.3f}\")\n",
    "\n",
    "\n",
    "# Get feature names after encoding\n",
    "encoded_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_vars)\n",
    "all_feature_names = numeric_vars + list(encoded_feature_names)\n",
    "\n",
    "# Plot the regression tree\n",
    "reg_tree = pipeline.named_steps['regressor']\n",
    "\n",
    "plt.figure(figsize=(30, 20))\n",
    "plot_tree(reg_tree,\n",
    "          feature_names=all_feature_names,\n",
    "          filled=True,\n",
    "          rounded=True,)\n",
    "plt.title(\"Decision Tree Regressor for Ejection Fraction\")\n",
    "plt.show()\n",
    "\n",
    "# very strano, assegno un numero preciso alla fine che varia poco, fisso e quindi modello inutile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Random forest classification problem\n",
    "# the evolution of trees, this allows to reduce the variance\n",
    "# ------------------------------\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42) # n_estimators is the tree number\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {acc:.3f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "\n",
    "# Finetune hyperparameters. Each tree is looking for a subset of the data\n",
    "# using cross validation \n",
    "\n",
    "# Define parameter grid, what I want to try\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_depth': [None, 3, 5, 10],\n",
    "    'max_features': ['sqrt', 'log2', None]  # or you can use int values\n",
    "}\n",
    "\n",
    "# Setup grid search\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1) # usa stratified se modello di classificazione\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model parameters\n",
    "best_rf = grid_search.best_estimator_\n",
    "print(f\"\\nBest Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV Accuracy: {grid_search.best_score_:.3f}\")\n",
    "\n",
    "# Test performance\n",
    "y_pred = best_rf.predict(X_test)\n",
    "print(\"\\nTest Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Out-of-Bag evaluation\n",
    "# is a way to do cross validation very efficient in term of computational power.\n",
    "# Si basa sul fatto che i trees in each forest not really use all the data, \n",
    "# but for each tree you are resample n points (sample with a replacement). Possono esserci\n",
    "# dei punti mai usati per il training (questo free senza rifittare il modello, guardando a ogni punto)\n",
    "# Averaging on all the points is an approx of cross validation\n",
    "# ------------------------------\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "rf_oob = RandomForestClassifier(oob_score=True, n_estimators=100, random_state=42)\n",
    "rf_oob.fit(X, y)\n",
    "print(\"OOB Score:\", rf_oob.oob_score_)\n",
    "\n",
    "\n",
    "# Metrics computing\n",
    "# The scikit-learn OOB implementation is limited to accuracy for classification and R^2 for regression. Other metrics can be computed by accessing the OOB predictions\n",
    "y_pred_oob = np.argmax(rf_oob.oob_decision_function_, axis=1)\n",
    "f1 = f1_score(y, y_pred_oob, average='macro')\n",
    "print(f\"OOB F1 Score (macro): {f1:.3f}\")\n",
    "\n",
    "\n",
    "# plot importance for variables\n",
    "\n",
    "importances = best_rf.feature_importances_\n",
    "sorted_idx = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(np.array(feature_names)[sorted_idx], importances[sorted_idx])\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"Random Forest Feature Importance\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "# or also\n",
    "\n",
    "\n",
    "# Feature importances\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "top10_rf = importances.sort_values(ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=top10_rf.values, y=top10_rf.index)\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.title(\"Top 10 Features  Random Forest\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('rf_top10.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# partial depencency plots \n",
    "# ------------------------------\n",
    "# You can use it with all types of model \n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 8))  # Adjust as needed\n",
    "PartialDependenceDisplay.from_estimator(best_rf, X, features=[0, 1, 2, 3], feature_names=feature_names, target=1, ax=ax) # target=1, 1 output class\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Random forest regression problem\n",
    "# ------------------------------\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Separate features/target\n",
    "X = df.drop(columns='ejection_fraction')\n",
    "y = df['ejection_fraction']\n",
    "\n",
    "numeric_vars = num_vars.copy()\n",
    "numeric_vars.remove('ejection_fraction')\n",
    "categorical_vars = cat_vars.copy()\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_vars),\n",
    "    ('cat', OneHotEncoder(drop='first'), categorical_vars)\n",
    "])\n",
    "\n",
    "# Full pipeline with RandomForestRegressor\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(n_estimators=100, random_state=42, oob_score=True))\n",
    "])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit model\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Adjusted R²\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "n = len(y_test)\n",
    "p = preprocessor.fit(X_train).transform(X_train).shape[1]\n",
    "adj_r2 = 1 - ((1 - r2) * (n - 1)) / (n - p - 1)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Output\n",
    "rf_model = pipeline.named_steps['model']\n",
    "print(f\"OOB R²: {rf_model.oob_score_:.3f}\") # posso calcolarlo sempre\n",
    "print(f\"R²:        {r2:.3f}\")\n",
    "print(f\"Adjusted R²:    {adj_r2:.3f}\")\n",
    "print(f\"MSE:            {mse:.2f}\")\n",
    "print(f\"MAE:            {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# gradient Boosting regressor\n",
    "# ------------------------------\n",
    "# instead of having in parallel all trees of random forest (bagging), it use a sequential\n",
    "# alg where each tree can see the other. model in output is more powerful\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Separate features/target\n",
    "X = df.drop(columns='ejection_fraction')\n",
    "y = df['ejection_fraction']\n",
    "\n",
    "numeric_vars = num_vars.copy()\n",
    "numeric_vars.remove('ejection_fraction')\n",
    "categorical_vars = cat_vars.copy()\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_vars),\n",
    "    ('cat', OneHotEncoder(drop='first'), categorical_vars)\n",
    "])\n",
    "\n",
    "# Pipeline with Gradient Boosting\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', GradientBoostingRegressor( \n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1, # new hyperparam\n",
    "        max_depth=3,\n",
    "        random_state=42))\n",
    "])\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit model\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Adjusted R²\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "n = len(y_test)\n",
    "p = preprocessor.fit(X_train).transform(X_train).shape[1]\n",
    "adj_r2 = 1 - ((1 - r2) * (n - 1)) / (n - p - 1)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Output\n",
    "print(f\"R²:        {r2:.3f}\")\n",
    "print(f\"Adjusted R²:    {adj_r2:.3f}\")\n",
    "print(f\"MSE:            {mse:.2f}\")\n",
    "print(f\"MAE:            {mae:.2f}\")\n",
    "\n",
    "# Random forest applica al radice di p per regression e p/3 il suo, quindi rimane fuori una parte\n",
    "# quella viene usata per la classificazione se obb attivo\n",
    "\n",
    "# bagging non splitta, usa tutto dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here a resume for all sklearn methods and classes and how they works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Standard scaler\n",
    "# --------------------------\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# Sensitive to outliers. Soliti metodi di:\n",
    "# fit(x), fit_transform(X), transform(X), get_feature_names_out(), get_params()\n",
    "# inverse_transform(X) Scale back the data to the original representation.\n",
    "# \n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# PCA\n",
    "# --------------------------\n",
    "\n",
    "pca = PCA(n_components=n_components)# possibile anche passargli random_state\n",
    "# Metodi contenuti:\n",
    "# - components_ : ndarray of shape (n_components, n_features)\n",
    "# - explained_variance_ : ndarray of shape (n_components,)\n",
    "# - explained_variance_ratio_ : ndarray of shape (n_components,)\n",
    "# - n_components_ : int\n",
    "# - n_samples_ : int\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# KMeans\n",
    "# --------------------------\n",
    "\n",
    "\n",
    "model = KMeans(n_clusters=3, random_state=42).fit(X)\n",
    "# - n_clusters=8\n",
    "# - init='k-means++'\n",
    "# - n_init='auto', is consecutive runs in terms of inertia\n",
    "# - max_iter=300 \n",
    "# - tol=0.0001 \n",
    "# - verbose=0 \n",
    "# - random_state=None \n",
    "# - copy_x=True \n",
    "# - algorithm='lloyd'\n",
    "# There are methods like:\n",
    "# - cluster_centers_ -> ndarray of shape (n_clusters, n_features)\n",
    "# - labels_ -> ndarray of shape (n_samples,)\n",
    "# - fit_predict(X) -> predict cluster index for each sample\n",
    "# - fit_transform(X) -> Compute clustering and transform X to cluster-distance space\n",
    "# - get_feature_names_out()\n",
    "# - inertia_ -> return the WSS\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# GMM\n",
    "# --------------------------\n",
    "\n",
    "\n",
    "gmm = GaussianMixture(n_components=3, covariance_type='full', random_state=42)#\n",
    "# Input params:\n",
    "# n_components=1\n",
    "# covariance_type='full' # {‘full’, ‘tied’, ‘diag’, ‘spherical’}\n",
    "# tol=0.001\n",
    "# reg_covar=1e-06 # Non-negative regularization added to the diagonal of covariance.\n",
    "# max_iter=100\n",
    "# n_init=1\n",
    "# init_params='kmeans', \n",
    "# weights_init=None, \n",
    "# means_init=None, \n",
    "# precisions_init=None, \n",
    "# random_state=None, \n",
    "# warm_start=False, # If ‘warm_start’ is True, the solution of the last fitting is used as initialization for the next call of fit(). \n",
    "# verbose=0, \n",
    "# verbose_interval=10\n",
    "\n",
    "# Other attributes:\n",
    "# weights_ : array-like of shape (n_components,)\n",
    "# means_ : array-like of shape (n_components, n_features)\n",
    "# covariances_ : array-like, The covariance of each mixture component.\n",
    "# precisions_ : array-like. The precision matrices for each component in the mixture. A precision matrix is the inverse of a covariance matrix.\n",
    "# converged_ : true or false, indica convergenza raggiunta o meno\n",
    "\n",
    "# Methods:\n",
    "# aic(x), with x = array of shape (n_samples, n_dimensions)\n",
    "# bic(x)\n",
    "# fit_predict(x)\n",
    "# get_params()\n",
    "# score(x) # Compute the per-sample average log-likelihood of the given data X.\n",
    "# score_samples(x) # Compute the log-likelihood of each sample.\n",
    "gmm.fit(iris)\n",
    "clusters = gmm.predict(iris)\n",
    "probabilities = gmm.predict_proba(iris)\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# LDA and QDA\n",
    "# --------------------------\n",
    "\n",
    "\n",
    "lda = LinearDiscriminantAnalysis() # methods calling obj:\n",
    "# coef_ : ndarray of shape (n_features,) or (n_classes, n_features). Are the Weight vector(s).\n",
    "# intercept_ : ndarray of shape (n_classes,)\n",
    "# covariance_ : array-like of shape (n_features, n_features)\n",
    "# predict_log_proba()\n",
    "# predict_proba()\n",
    "# predict()\n",
    "# fit()\n",
    "# You can set also the:\n",
    "# - priors=[0.1,0.9]\n",
    "# - n_components\n",
    "lda.fit(X, y)\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Polynomial degree elevation for regression\n",
    "# --------------------------\n",
    "\n",
    "polynomial2 = PolynomialFeatures(degree=2, include_bias=True)\n",
    "# include bias is beta0\n",
    "X_train_6 = polynomial2.fit_transform(X_train_6)\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# OneHot Encoding\n",
    "# --------------------------\n",
    "\n",
    "\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "# using drop, meaning that you take the first as base variable\n",
    "encoded_feature = encoder.fit_transform(df[X_categorical_vars_names])\n",
    "df_encoded = pd.DataFrame(encoded_feature, columns=encoder.get_feature_names_out(X_categorical_vars_names))\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Column transformer\n",
    "# --------------------------\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_vars),\n",
    "    ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_vars)\n",
    "])\n",
    "# other methods: fit(X), get_feature_names_out(), get_params(), \n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_test_proc = preprocessor.transform(X_test)\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Linear regression\n",
    "# --------------------------\n",
    "\n",
    "\n",
    "ols_model = LinearRegression()\n",
    "# Inputs are:\n",
    "# - fit_intercept: bool = True, Whether to calculate the intercept for this model.\n",
    "# - copy_X: bool = True, If True, X will be copied; else, it may be overwritten.\n",
    "# - positive: bool = False, When set to True, forces the coefficients to be positive. This option is only supported for dense arrays.\n",
    "# Methods are:\n",
    "# coef_: array of shape (n_features, ) or (n_targets, n_features)\n",
    "# rank_int : Rank of matrix X\n",
    "# intercept_ : float or array of shape (n_targets,)\n",
    "# n_features_in_: int\n",
    "# fit(X, y)\n",
    "# get_params(), \n",
    "# predict(X)\n",
    "# score(X, y_true) : R squared\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Feature selection\n",
    "# --------------------------\n",
    "\n",
    "efs = ExhaustiveFeatureSelector(LinearRegression(), min_features=1, max_features=10, scoring='r2', cv=5)\n",
    "\n",
    "\n",
    "\n",
    "sfs_forward = SequentialFeatureSelector(LinearRegression(), direction='forward', cv=5, scoring='r2')\n",
    "# n_features_to_select : “auto”, int or float, default=”auto”\n",
    "# direction: Literal['forward', 'backward'] = \"forward\",\n",
    "# tol\n",
    "# cv: Iterable | int | BaseCrossValidator = 5\n",
    "# scoring : str or callable, default=None, Usato dalla cross validation. the names are:\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-string-names\n",
    "# Methods:\n",
    "# support_ : ndarray of shape (n_features,), dtype=bool. The mask of selected features.\n",
    "# fit(x), fit_transform(X), get_feature_names_out(), get_params(), \n",
    "# get_support() : Get a mask, or integer index, of the features selected.\n",
    "# inverse_transform(X) : Reverse the transformation operation.\n",
    "# set_params() : Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as Pipeline)\n",
    "# transform()\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Logistic Regression\n",
    "# --------------------------\n",
    "\n",
    "logreg_full = LogisticRegression() # inputs are:\n",
    "# penalty{‘l1’, ‘l2’, ‘elasticnet’, None}, default=’l2’\n",
    "# fit_intercept : bool, default=True. Specifies if a constant (a.k.a. bias or intercept) should be added to the decision function.\n",
    "# random_state\n",
    "# solver{‘lbfgs’, ‘liblinear’, ‘newton-cg’, ‘newton-cholesky’, ‘sag’, ‘saga’}\n",
    "# max_iter : int, default=100\n",
    "# multi_class {‘auto’, ‘ovr’, ‘multinomial’}, default=’auto’\n",
    "# Attributes are:\n",
    "# classes_\n",
    "# coef_ : ndarray of shape (1, n_features) or (n_classes, n_features)\n",
    "# intercept_ : ndarray of shape (1,) or (n_classes,)\n",
    "# Methods:\n",
    "# decision_function(X) : Predict confidence scores for samples.\n",
    "# fit(X, y)\n",
    "# predict(X)\n",
    "# predict_log_proba(X)\n",
    "# predict_proba(X)\n",
    "# score(X, y_true) : is the accuracy score\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Pipeline\n",
    "# --------------------------\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', selector),\n",
    "    ('regressor', regressor)\n",
    "])\n",
    "# where preprocessor is the Column transformer.\n",
    "# feature_selection is the SequentialFeatureSelector obj\n",
    "# regressor is the LinearRegression obj\n",
    "# Methods:\n",
    "# decision_function(X, **params) : Transform the data, and apply decision_function with the final estimator\n",
    "# fit(X), Fit all the transformers one after the other and sequentially transform the data.\n",
    "# fit_predict(X)\n",
    "# fit_transform(X)\n",
    "# get_feature_names_out(), get_params(), predict(X), predict_log_proba(X), predict_proba(X)\n",
    "# All this method are valid if the last has got those methods\n",
    "reg_tree = pipeline.named_steps['regressor'] # access to specific inside pipeline\n",
    "\n",
    "# --------------------------\n",
    "# Ridge (or Lasso is the same)\n",
    "# --------------------------\n",
    "\n",
    "rd = Ridge(alpha=100, max_iter=100, tol=0.001, random_state=42, solver='svd')\n",
    "# methods:\n",
    "# fit(X), predict(X), coef_, intercept_\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# DecisionTreeClassifier\n",
    "# --------------------------\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=42, ccp_alpha=alpha) # max_depth is very important\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "scoringg = clf.score(X_train, y_train)\n",
    "importances = clf.feature_importances_\n",
    "path = clf.cost_complexity_pruning_path(X_train, y_train) # provides a set of alphas that are relevants\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Random Forest\n",
    "# --------------------------\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42, oob_score=False)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Gradient Boosting Regressor\n",
    "# --------------------------\n",
    "\n",
    "p =  GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "p.fit(X_train, y_train)\n",
    "y_pred = p.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "\n",
    "# --------------------------\n",
    "# Cross validation\n",
    "# --------------------------\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "kf = LeaveOneOut()\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0) # Class-wise stratified K-Fold cross-validator.\n",
    "\n",
    "# singola metrica\n",
    "scores = cross_val_score(pipeline, X, y, scoring=make_scorer(r2_score), cv=kf)\n",
    "# scores is: ndarray of float of shape=(len(list(cv)),)\n",
    "\n",
    "# metriche multiple\n",
    "cv_results_ridge = cross_validate(ridge_pipeline, X, y, cv=5, scoring=scoring)\n",
    "# Evaluate metric(s) by cross-validation and also record fit/score times.\n",
    "\n",
    "\n",
    "lasso_params = {'regressor__alpha': np.logspace(-3, 3, 50)}\n",
    "eva = GridSearchCV(lasso_pipeline, lasso_params, cv=5)\n",
    "# It recieve in input:\n",
    "# - estimator obj: Either estimator needs to provide a score function, or scoring must be passed\n",
    "# - param_grid : dict or list of dictionaries\n",
    "# - scoring : str, callable, list, tuple or dict, default=None, \n",
    "# Attributes:\n",
    "# cv_results_ : dict of numpy (masked) ndarrays\n",
    "# best_estimator_ : Estimator that was chosen by the search, i.e. estimator which gave highest score\n",
    "# best_score_, best_params_, best_index_ (The index (of the cv_results_ arrays) which corresponds to the best candidate parameter setting.)\n",
    "# scorer_ : Scorer function used on the held out data to choose the best parameters for the model.\n",
    "# Methods:\n",
    "# decision_function(X) : Call decision_function on the estimator with the best found parameters.\n",
    "# fit(X), predict(X), predict_log_proba(X), predict_proba(X), score(X), transform(X)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPMChU5wnBU4SYtxXoNXrX3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
